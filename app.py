import streamlit as st
import time
import google.generativeai as genai
from openai import OpenAI
import speech_recognition as sr
from streamlit_mic_recorder import mic_recorder
from io import BytesIO

# ===== 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© =====
st.set_page_config(page_title="Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø¨Ø´Ø±ÙŠ", page_icon="ğŸ—£ï¸", layout="centered")

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ÙØ§ØªÙŠØ­ API (ÙŠØ¬Ø¨ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯Ù‡Ø§) ---
try:
    # 1. Ù…ÙØªØ§Ø­ Ø¬ÙˆØ¬Ù„ (Ù„Ù„ØªÙÙƒÙŠØ± ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø©)
    if "GOOGLE_API_KEY" in st.secrets:
        genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    else:
        st.error("Ù…ÙØªØ§Ø­ GOOGLE_API_KEY Ù…ÙÙ‚ÙˆØ¯ ÙÙŠ Ø§Ù„Ù€ Secrets")
        st.stop()

    # 2. Ù…ÙØªØ§Ø­ OpenAI (Ù„Ù„ØµÙˆØª Ø§Ù„Ø¨Ø´Ø±ÙŠ)
    if "OPENAI_API_KEY" in st.secrets:
        openai_client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
    else:
        st.error("Ù…ÙØªØ§Ø­ OPENAI_API_KEY Ù…ÙÙ‚ÙˆØ¯ ÙÙŠ Ø§Ù„Ù€ Secrets. Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ´ØºÙŠÙ„ Ø§Ù„ØµÙˆØª Ø§Ù„Ø¨Ø´Ø±ÙŠ Ø¨Ø¯ÙˆÙ†Ù‡.")
        st.stop()

except Exception as e:
    st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª: {e}")
    st.stop()

# --- Ø¯Ø§Ù„Ø© Ù†Ø·Ù‚ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenAI (Ø¬ÙˆØ¯Ø© Ø¨Ø´Ø±ÙŠØ©) ---
def generate_human_audio(text, output_file, voice_name):
    try:
        response = openai_client.audio.speech.create(
            model="tts-1",       # Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹ ÙˆØ§Ù„ÙˆØ§Ù‚Ø¹ÙŠ
            voice=voice_name,    # Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø®ØªØ§Ø±
            input=text
        )
        response.stream_to_file(output_file)
        return True
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª: {e}")
        return False

# --- Ø¯Ø§Ù„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ù„Ù†Øµ ---
def speech_to_text(audio_bytes):
    r = sr.Recognizer()
    try:
        audio_file = sr.AudioFile(BytesIO(audio_bytes))
        with audio_file as source:
            r.adjust_for_ambient_noise(source)
            audio_data = r.record(source)
            # Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ©
            text = r.recognize_google(audio_data, language="ar-EG")
            return text
    except sr.UnknownValueError:
        return None
    except Exception as e:
        return None

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ÙˆØ¯ÙŠÙ„ Ø¬ÙˆØ¬Ù„ ---
try:
    all_models = genai.list_models()
    my_models = [m.name for m in all_models if 'generateContent' in m.supported_generation_methods]
    
    # Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„ Ù…ØªØ§Ø­ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
    active_model_name = next((m for m in my_models if 'flash' in m), None)
    if not active_model_name:
        active_model_name = next((m for m in my_models if 'pro' in m), my_models[0])
        
    model = genai.GenerativeModel(active_model_name)
except:
    st.error("ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø¬ÙˆØ¬Ù„."); st.stop()

# ===== 2. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© =====
st.title("ğŸ™ï¸ Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„ØµÙˆØªÙŠ (Ø¬ÙˆØ¯Ø© Ø¨Ø´Ø±ÙŠØ©)")
st.caption("âœ… Ø§Ù„ØªÙÙƒÙŠØ±: Google Gemini | âœ… Ø§Ù„ØµÙˆØª: OpenAI TTS")

# --- Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø£ØµÙˆØ§Øª Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ù…Ù† OpenAI ---
st.subheader("ğŸ”Š Ø§Ø®ØªØ± Ù†Ø¨Ø±Ø© Ø§Ù„ØµÙˆØª")
voice_options = {
    "ğŸ‘¨â€ğŸ« ØµÙˆØª Ø±Ø¬Ø§Ù„ÙŠ Ø¹Ù…ÙŠÙ‚ ÙˆØ±Ø²ÙŠÙ† (Onyx)": "onyx",
    "ğŸ‘¨â€ğŸ’¼ ØµÙˆØª Ø±Ø¬Ø§Ù„ÙŠ Ù…ØªÙˆØ§Ø²Ù† (Echo)": "echo",
    "ğŸ‘©â€ğŸ« ØµÙˆØª Ù†Ø³Ø§Ø¦ÙŠ Ø­ÙŠÙˆÙŠ (Shimmer)": "shimmer",
    "ğŸ‘©â€ğŸ’¼ ØµÙˆØª Ù†Ø³Ø§Ø¦ÙŠ Ù‡Ø§Ø¯Ø¦ (Nova)": "nova"
}
selected_voice_label = st.selectbox("Ø§Ù„Ù…Ø¹Ù„Ù‚ Ø§Ù„ØµÙˆØªÙŠ:", list(voice_options.keys()))
selected_voice_code = voice_options[selected_voice_label]

# ===== 3. Ø§Ù„Ø¯Ø®ÙˆÙ„ =====
if "logged_in" not in st.session_state:
    password = st.text_input("ğŸ”‘ Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ø³Ø±ÙŠ", type="password")
    if password == "SCIENCE60":
        st.session_state.logged_in = True
        st.rerun()
    elif password: st.warning("Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ø³Ø±ÙŠ")
    st.stop()

# ===== 4. Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© =====
st.markdown("---")
st.write("Ø§Ø¶ØºØ· ÙˆØªØ­Ø¯Ø«ØŒ ÙˆØ³Ø£Ø¬ÙŠØ¨Ùƒ Ø¨ØµÙˆØª Ø¨Ø´Ø±ÙŠ Ø·Ø¨ÙŠØ¹ÙŠ:")

audio_input = mic_recorder(
    start_prompt="ğŸ¤ ØªØ­Ø¯Ø« Ø§Ù„Ø¢Ù†",
    stop_prompt="â¹ï¸ Ø¥Ø±Ø³Ø§Ù„",
    key='recorder',
    format="wav"
)

if audio_input:
    with st.spinner("ğŸ‘‚ Ø£Ø³ØªÙ…Ø¹ Ø¥Ù„ÙŠÙƒ..."):
        user_text = speech_to_text(audio_input['bytes'])
    
    if user_text:
        st.success(f"ğŸ—£ï¸ Ø³Ø¤Ø§Ù„Ùƒ: {user_text}")
        with st.spinner("ğŸ§  ÙˆØµÙˆØª Ø¨Ø´Ø±ÙŠ ÙŠØªÙ… ØªØ­Ø¶ÙŠØ±Ù‡..."):
            try:
                # Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù†Øµ Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ©
                prompt = f"""
                Ø£Ù†Øª Ù…Ø¹Ù„Ù… Ù…ØµØ±ÙŠ Ù…Ø®Ø¶Ø±Ù….
                Ø§Ù„Ø³Ø¤Ø§Ù„: '{user_text}'
                
                Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª:
                1. Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ© Ø§Ù„Ø¹Ø§Ù…ÙŠØ© "Ø§Ù„Ù…Ø­ØªØ±Ù…Ø©" (Ù„ØºØ© Ø§Ù„Ù…Ø«Ù‚ÙÙŠÙ†).
                2. ØªØ¬Ù†Ø¨ Ø§Ù„Ø±Ù…ÙˆØ² ØªÙ…Ø§Ù…Ø§Ù‹ (* Ø£Ùˆ -).
                3. Ø§Ø³ØªØ®Ø¯Ù… Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… (ØŒ .) Ø¨ÙƒØ«Ø±Ø© Ù„Ø£Ù† Ø§Ù„ØµÙˆØª Ø§Ù„Ø¨Ø´Ø±ÙŠ ÙŠØ­ØªØ§Ø¬ Ù„Ù„ØªÙ†ÙØ³.
                4. Ø§Ø¬Ø¹Ù„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø±ÙƒØ²Ø© ÙˆÙ‚ØµÙŠØ±Ø©.
                """
                
                # 1. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†Øµ Ù…Ù† Ø¬ÙˆØ¬Ù„
                gemini_response = model.generate_content(prompt)
                answer_text = gemini_response.text
                
                st.markdown(f"### ğŸ“˜ Ø§Ù„Ø±Ø¯:\n{answer_text}")
                
                # 2. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª Ù…Ù† OpenAI
                output_file = "human_response.mp3"
                success = generate_human_audio(answer_text, output_file, selected_voice_code)
                
                if success:
                    st.audio(output_file, format='audio/mp3', autoplay=True)
                
            except Exception as e:
                st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")
    else:
        st.warning("âš ï¸ Ø§Ù„ØµÙˆØª ØºÙŠØ± ÙˆØ§Ø¶Ø­ØŒ Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")
