import streamlit as st
import time
import google.generativeai as genai
import asyncio
import edge_tts
import speech_recognition as sr
from streamlit_mic_recorder import mic_recorder
from io import BytesIO
import re

# ===== 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© =====
st.set_page_config(page_title="Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ù…ØµØ±ÙŠ", page_icon="ğŸ‡ªğŸ‡¬", layout="centered")

# --- Ø¯Ø§Ù„Ø© ØªÙ†Ø¸ÙŠÙ Ø°ÙƒÙŠØ© (ØªØ¨Ù‚ÙŠ Ø¹Ù„Ù‰ Ø§Ù„ÙÙˆØ§ØµÙ„ Ù„Ù„Ù†ÙØ³) ---
def prepare_text_for_audio(text):
    # Ù†Ø²ÙŠÙ„ Ø§Ù„Ù†Ø¬ÙˆÙ… ÙˆØ§Ù„Ø±Ù…ÙˆØ² Ø§Ù„ØªÙŠ Ù„Ø§ ØªÙÙ†Ø·Ù‚
    text = text.replace("*", "")
    text = text.replace("#", "")
    text = text.replace("- ", "")
    text = text.replace('"', "")
    # Ù†ÙØ¨Ù‚ÙŠ Ø¹Ù„Ù‰ Ø§Ù„ÙÙˆØ§ØµÙ„ ÙˆØ§Ù„Ù†Ù‚Ø§Ø· Ù„Ø£Ù†Ù‡Ø§ Ù…Ù‡Ù…Ø© Ø¬Ø¯Ø§Ù‹ Ù„Ù„ØªÙ†ÙØ³ ÙÙŠ Ø§Ù„ÙƒÙ„Ø§Ù…
    return text

# --- Ø¯Ø§Ù„Ø© Ù†Ø·Ù‚ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© (Ø¶Ø¨Ø· Ø¯Ù‚ÙŠÙ‚ Ù„Ù„Ø³Ø±Ø¹Ø©) ---
async def generate_speech(text, output_file, voice_code):
    clean_text = prepare_text_for_audio(text)
    # rate="-5%" : ØªØ¨Ø·ÙŠØ¡ Ø·ÙÙŠÙ Ø¬Ø¯Ø§Ù‹ ÙŠØ¹Ø·ÙŠ Ø±Ø²Ø§Ù†Ø© Ø¯ÙˆÙ† Ù…Ù„Ù„
    communicate = edge_tts.Communicate(clean_text, voice_code, rate="-5%")
    await communicate.save(output_file)

# --- Ø¯Ø§Ù„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ù„Ù†Øµ ---
def speech_to_text(audio_bytes):
    r = sr.Recognizer()
    try:
        audio_file = sr.AudioFile(BytesIO(audio_bytes))
        with audio_file as source:
            r.adjust_for_ambient_noise(source)
            audio_data = r.record(source)
            text = r.recognize_google(audio_data, language="ar-EG")
            return text
    except:
        return None

# --- Ø§Ù„Ø§ØªØµØ§Ù„ Ø§Ù„Ø°ÙƒÙŠ ---
active_model_name = "ØºÙŠØ± Ù…ØªØµÙ„"
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
    
    all_models = genai.list_models()
    my_models = [m.name for m in all_models if 'generateContent' in m.supported_generation_methods]
    
    if not my_models: st.error("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…ÙˆØ¯ÙŠÙ„Ø§Øª"); st.stop()
        
    preferred_model = next((m for m in my_models if 'flash' in m), None)
    if not preferred_model:
        preferred_model = next((m for m in my_models if 'pro' in m), my_models[0])
        
    active_model_name = preferred_model
    model = genai.GenerativeModel(active_model_name)
    
except Exception as e:
    st.error(f"âš ï¸ Ø®Ø·Ø£: {e}"); st.stop()

# ===== 2. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© =====
st.title("ğŸ‡ªğŸ‡¬ Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ù…ØµØ±ÙŠ (Ø¯Ø±ÙˆØ³ Ø®ØµÙˆØµÙŠØ©)")
st.caption("ÙŠØ¹Ù…Ù„ Ø¨Ù„Ù‡Ø¬Ø© Ø§Ù„Ø¯Ø±ÙˆØ³ Ø§Ù„Ø®ØµÙˆØµÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ©")

# --- Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØµÙˆØª ---
st.subheader("ğŸ”Š Ø§Ø®ØªØ± Ø§Ù„Ù…Ø¯Ø±Ø³")
voice_options = {
    "ğŸ‘¨â€ğŸ« Ù…Ø³ØªØ± Ø´Ø§ÙƒØ± (Ø£Ø¯Ø§Ø¡ Ø¯Ø±Ø§Ù…ÙŠ)": "ar-EG-ShakirNeural",
    "ğŸ‘©â€ğŸ« Ù…Ø³ Ø³Ù„Ù…Ù‰ (Ø£Ø¯Ø§Ø¡ Ù‡Ø§Ø¯Ø¦)": "ar-EG-SalmaNeural"
}
selected_voice_name = st.selectbox("Ù…ÙŠÙ† Ù‡ÙŠØ´Ø±Ø­Ù„ÙƒØŸ", list(voice_options.keys()))
selected_voice_code = voice_options[selected_voice_name]

# ===== 3. Ø§Ù„Ø¯Ø®ÙˆÙ„ =====
if "logged_in" not in st.session_state:
    password = st.text_input("ğŸ”‘ Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ø³Ø±ÙŠ", type="password")
    if password == "SCIENCE60":
        st.session_state.logged_in = True
        st.rerun()
    elif password: st.warning("Ø§Ù„Ø¨Ø§Ø³ÙˆØ±Ø¯ ØºÙ„Ø·")
    st.stop()

# ===== 4. Ø§Ù„Ø¹Ø¯Ø§Ø¯ =====
if "start_time" not in st.session_state: st.session_state.start_time = time.time()
remaining = 3600 - (time.time() - st.session_state.start_time)
if remaining <= 0: st.error("Ø§Ù„Ø­ØµØ© Ø®Ù„ØµØª!"); st.stop()
st.info(f"â³ Ø¨Ø§Ù‚ÙŠ: {int(remaining//60)} Ø¯Ù‚ÙŠÙ‚Ø©")

# ===== 5. Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© =====
st.markdown("---")
st.subheader("Ø§Ø¨Ø¯Ø£ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ğŸ‘‡")

audio_input = mic_recorder(
    start_prompt="ğŸ¤ Ø¯ÙˆØ³ Ù‡Ù†Ø§ ÙˆØ§Ø³Ø£Ù„",
    stop_prompt="â¹ï¸ Ø§Ø¨Ø¹Øª Ø§Ù„Ø³Ø¤Ø§Ù„",
    key='recorder',
    format="wav"
)

if audio_input:
    with st.spinner("ğŸ‘‚ Ø¨Ø³Ù…Ø¹Ùƒ..."):
        user_text = speech_to_text(audio_input['bytes'])
    
    if user_text:
        st.success(f"ğŸ—£ï¸ Ø£Ù†Øª: {user_text}")
        with st.spinner("ğŸ§  Ø¨Ø¬Ù‡Ù‘Ø² Ø§Ù„Ø±Ø¯..."):
            try:
                role = "Ù…ÙØ¯Ø±Ø³Ø© Ø¹Ù„ÙˆÙ… Ø´Ø§Ø·Ø±Ø©" if "Ø³Ù„Ù…Ù‰" in selected_voice_name else "Ù…ÙØ¯Ø±Ø³ Ø¹Ù„ÙˆÙ… Ø´Ø§Ø·Ø±"
                
                # --- Ø³Ø± Ø§Ù„Ø®Ù„Ø·Ø© Ø§Ù„Ù…ØµØ±ÙŠØ© (Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠ) ---
                prompt = f"""
                Ø£Ù†Øª {role} Ø¨ØªØ¯ÙŠ Ø¯Ø±ÙˆØ³ Ø®ØµÙˆØµÙŠØ© Ù„Ø·Ù„Ø§Ø¨ ÙÙŠ Ù…ØµØ±.
                Ø§Ù„Ø·Ø§Ù„Ø¨ Ø³Ø£Ù„Ùƒ: '{user_text}'
                
                Ù…Ù‡Ù…ØªÙƒ: Ø§Ø´Ø±Ø­ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙƒØ£Ù†Ùƒ Ø¨ØªØªÙƒÙ„Ù… ØµÙˆØªÙŠ Ù…Ø´ Ø¨ØªÙƒØªØ¨.
                
                Ù‚ÙˆØ§Ø¹Ø¯ ØµØ§Ø±Ù…Ø© Ø¬Ø¯Ø§Ù‹ Ù„Ù„Ù‡Ø¬Ø©:
                1. Ø§Ø³ØªØ®Ø¯Ù… "Ø§Ù„ÙÙˆØ§ØµÙ„" (ØŒ) ÙƒØªÙŠØ± Ø¬Ø¯Ø§Ù‹ Ø¨ÙŠÙ† Ø§Ù„Ø¬Ù…Ù„ØŒ Ø¹Ø´Ø§Ù† Ø§Ù„Ù‚Ø§Ø±Ø¦ ÙŠØ§Ø®Ø¯ Ù†ÙØ³Ù‡ ÙˆÙŠØ¨Ù‚Ù‰ Ø§Ù„ØµÙˆØª Ø·Ø¨ÙŠØ¹ÙŠ.
                2. Ø´ÙƒÙ‘Ù„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¹Ø§Ù…ÙŠØ© Ø¹Ø´Ø§Ù† ØªØªÙ†Ø·Ù‚ ØµØ­. Ø§ÙƒØªØ¨: (ÙƒÙØ¯ÙÙ‡ØŒ Ø¯ÙÙ‡ØŒ Ø·ÙØ¨Ù’Ø¹Ø§Ù‹ØŒ Ø¨ÙØ³ØŒ Ø¹ÙØ´ÙØ§Ù†ØŒ Ø¯ÙÙ„Ù’ÙˆÙÙ‚Ù’ØªÙÙŠ).
                3. Ø§Ø³ØªØ®Ø¯Ù… "Ù‡Ù€" Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ© (Ù‡Ù†Ø´ÙˆÙØŒ Ù‡Ù†Ø¹Ù…Ù„) Ø¨Ø¯Ù„ "Ø³ÙˆÙ".
                4. Ø§Ø³ØªØ®Ø¯Ù… ÙƒÙ„Ù…Ø§Øª Ø±Ø¨Ø· Ù…ØµØ±ÙŠØ© Ø²ÙŠ: (Ø¨Øµ ÙŠØ§ Ø³ÙŠØ¯ÙŠØŒ Ø®Ø¯ Ø¨Ø§Ù„ÙƒØŒ ØªØ®ÙŠÙ„ Ù…Ø¹Ø§ÙŠØ§ØŒ Ø§Ù„Ù…Ù‡Ù…).
                5. Ø¨Ù„Ø§Ø´ ØªØ³ØªØ®Ø¯Ù… "Ø­ÙŠØ« Ø£Ù†" Ø£Ùˆ "Ù„Ø£Ù†"ØŒ Ø§Ø³ØªØ®Ø¯Ù… "Ø¹ÙØ´ÙØ§Ù†".
                6. Ù…Ù…Ù†ÙˆØ¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ù…Ø±Ù‚Ù…Ø© (1. 2.) Ø£Ùˆ Ø§Ù„Ù†Ø¬ÙˆÙ… (*). Ø§ØªÙƒÙ„Ù… ÙÙŠ ÙÙ‚Ø±Ø© Ù…ØªØµÙ„Ø© ÙˆÙ…Ø±ÙŠØ­Ø©.
                7. Ø®Ù„ÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù‚ØµÙŠØ±Ø© ÙˆÙ…ÙÙŠØ¯Ø© ÙˆÙ…Ù…ØªØ¹Ø©.
                
                Ù…Ø«Ø§Ù„ Ù„Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù„ÙŠ Ø¹Ø§ÙŠØ²Ùƒ ØªÙƒØªØ¨ Ø¨ÙŠÙ‡Ø§:
                "Ø¨Øµ ÙŠØ§ Ø¨Ø·Ù„ØŒØŒ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¯Ù‡ Ø°ÙƒÙŠ Ø¬Ø¯Ø§Ù‹.ØŒ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø¨Ø³Ø§Ø·Ø© Ù‡ÙŠ ÙƒÙØ°ÙØ§ ÙˆÙƒÙØ°ÙØ§.. ÙˆØ¹ÙØ´ÙØ§Ù† ØªÙÙ‡Ù…Ù‡Ø§ Ø£ÙƒØªØ±ØŒØŒ ØªØ®ÙŠÙ„ Ù„Ùˆ Ù…Ø¹Ø§Ù†Ø§ ÙƒÙˆØ±Ø©..."
                """
                
                response = model.generate_content(prompt)
                
                st.markdown(f"### ğŸ“˜ Ø§Ù„Ø±Ø¯:\n{response.text}")
                
                output_file = "response.mp3"
                asyncio.run(generate_speech(response.text, output_file, selected_voice_code))
                st.audio(output_file, format='audio/mp3', autoplay=True)
                
            except Exception as e:
                st.error(f"Ù…Ø´ÙƒÙ„Ø© ØªÙ‚Ù†ÙŠØ©: {e}")
    else:
        st.warning("âš ï¸ Ø§Ù„ØµÙˆØª Ù…Ø´ ÙˆØ§ØµÙ„ØŒ Ø¹Ù„ÙŠ ØµÙˆØªÙƒ Ø´ÙˆÙŠØ©.")

st.markdown("---")
