import streamlit as st
import nest_asyncio
from datetime import datetime
import google.generativeai as genai
import edge_tts
import speech_recognition as sr
from streamlit_mic_recorder import mic_recorder
from PIL import Image
from google.oauth2 import service_account
import gspread
from io import BytesIO
import asyncio

nest_asyncio.apply()
st.set_page_config(page_title="Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ", layout="wide")

# ØªØµÙ…ÙŠÙ… Ø¨Ø³ÙŠØ· ÙˆÙˆØ§Ø¶Ø­
st.markdown("""
<style>
* { color: black !important; font-family: sans-serif; }
.stApp { background: white; }
.msg { padding: 10px; border-radius: 8px; margin: 5px; border: 1px solid #ddd; }
.user { background: #E3F2FD; text-align: right; }
.bot { background: #F1F8E9; text-align: right; }
</style>
""", unsafe_allow_html=True)

# Ø¯ÙˆØ§Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø¬ÙˆØ¬Ù„ Ø´ÙŠØª (Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙƒÙˆØ¯ Ø§Ù„Ø·Ø§Ù„Ø¨)
def get_db():
    if "gcp_service_account" not in st.secrets: return None
    try:
        cred = service_account.Credentials.from_service_account_info(
            dict(st.secrets["gcp_service_account"]),
            scopes=['https://www.googleapis.com/auth/spreadsheets']
        )
        return gspread.authorize(cred)
    except: return None

def get_student_pass():
    client = get_db()
    if not client: return None
    try:
        # Ù‚Ø±Ø§Ø¡Ø© ÙƒÙ„Ù…Ø© Ø³Ø± Ø§Ù„Ø·Ø§Ù„Ø¨ Ù…Ù† Ø§Ù„Ø®Ù„ÙŠØ© B1
        return str(client.open("App_Control").sheet1.acell('B1').value).strip()
    except: return None

# Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
def get_ai(vision=False):
    keys = st.secrets.get("GOOGLE_API_KEYS", [])
    if not keys: return None
    import random
    genai.configure(api_key=random.choice(keys))
    if vision: return genai.GenerativeModel('gemini-pro-vision')
    return genai.GenerativeModel('gemini-pro')

# Ø§Ù„ØµÙˆØª
async def tts_gen(text):
    cm = edge_tts.Communicate(text, "ar-EG-ShakirNeural")
    out = BytesIO()
    async for ch in cm.stream():
        if ch["type"] == "audio": out.write(ch["data"])
    return out

def play_audio(txt):
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        aud = loop.run_until_complete(tts_gen(txt[:200]))
        st.audio(aud, format='audio/mp3', autoplay=True)
    except: pass

# ============================
# Ø§Ù„Ø´Ø§Ø´Ø© 1: ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ (ÙƒØ§Ù…Ù„Ø©)
# ============================
if "auth" not in st.session_state:
    st.session_state.auth = False
    st.session_state.msgs = []

if not st.session_state.auth:
    c1, c2, c3 = st.columns([1,2,1])
    with c2:
        st.title("ğŸ” ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„")
        st.info("Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ù…Ù†ØµØ© Ø§Ù„Ø¹Ù„ÙˆÙ…")
        
        with st.form("login_form"):
            # Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
            name = st.text_input("Ø§Ù„Ø§Ø³Ù…:")
            grade = st.selectbox("Ø§Ù„ØµÙ:", ["Ø§Ù„Ø±Ø§Ø¨Ø¹", "Ø§Ù„Ø®Ø§Ù…Ø³", "Ø§Ù„Ø³Ø§Ø¯Ø³", "Ø¥Ø¹Ø¯Ø§Ø¯ÙŠ", "Ø«Ø§Ù†ÙˆÙŠ"])
            code = st.text_input("ÙƒÙˆØ¯ Ø§Ù„Ø¯Ø®ÙˆÙ„:", type="password")
            
            # Ø²Ø± Ø§Ù„Ø¯Ø®ÙˆÙ„
            submitted = st.form_submit_button("Ø¯Ø®ÙˆÙ„")
            
            if submitted:
                real_student_pass = get_student_pass()
                admin_key = "ADMIN_2024"
                
                is_admin = (code == admin_key)
                is_student = (real_student_pass and code == real_student_pass)
                
                if is_admin or is_student:
                    st.session_state.auth = True
                    st.session_state.user = name
                    st.success("ØªÙ… Ø§Ù„Ø¯Ø®ÙˆÙ„!")
                    st.rerun()
                else:
                    st.error("Ø§Ù„ÙƒÙˆØ¯ ØºÙŠØ± ØµØ­ÙŠØ­")
    st.stop()

# ============================
# Ø§Ù„Ø´Ø§Ø´Ø© 2: Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
# ============================
st.sidebar.title(f"ğŸ‘¤ {st.session_state.user}")
if st.sidebar.button("Ø®Ø±ÙˆØ¬"):
    st.session_state.auth = False
    st.rerun()

st.title("ğŸ§¬ Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ")

t1, t2, t3 = st.tabs(["ğŸ™ï¸ ØµÙˆØª", "ğŸ“ ÙƒØªØ§Ø¨Ø©", "ğŸ“· ØµÙˆØ±Ø©"])

with t1:
    aud = mic_recorder(start_prompt="ğŸ¤ ØªØ­Ø¯Ø«", stop_prompt="â¹ï¸ ØªÙˆÙ‚Ù", key='mic')
    if aud:
        try:
            r = sr.Recognizer()
            src = sr.AudioFile(BytesIO(aud['bytes']))
            with src as s:
                r.adjust_for_ambient_noise(s)
                txt = r.recognize_google(r.record(s), language="ar-EG")
            st.success(f"Ù‚Ù„Øª: {txt}")
            m = get_ai()
            if m:
                ans = m.generate_content(f"Ø§Ø´Ø±Ø­ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ: {txt}").text
                st.session_state.msgs.append(("user", txt))
                st.session_state.msgs.append(("bot", ans))
        except: st.error("ØµÙˆØª ØºÙŠØ± ÙˆØ§Ø¶Ø­")

with t2:
    q = st.text_input("Ø³Ø¤Ø§Ù„Ùƒ:")
    if st.button("Ø¥Ø±Ø³Ø§Ù„") and q:
        m = get_ai()
        if m:
            ans = m.generate_content(f"Ø§Ø´Ø±Ø­ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ: {q}").text
            st.session_state.msgs.append(("user", q))
            st.session_state.msgs.append(("bot", ans))

with t3:
    up = st.file_uploader("ØµÙˆØ±Ø©", type=['png','jpg'])
    if up and st.button("ØªØ­Ù„ÙŠÙ„"):
        img = Image.open(up)
        st.image(img, width=150)
        m = get_ai(vision=True)
        if m:
            ans = m.generate_content(["Ø§Ø´Ø±Ø­ Ø§Ù„ØµÙˆØ±Ø©", img]).text
            st.session_state.msgs.append(("user", "ØµÙˆØ±Ø©"))
            st.session_state.msgs.append(("bot", ans))

st.divider()
for role, txt in reversed(st.session_state.msgs):
    cls = "user" if role == "user" else "bot"
    st.markdown(f"<div class='msg {cls}'>{txt}</div>", unsafe_allow_html=True)
    if role == "bot":
        if st.button("ğŸ”Š", key=str(hash(txt))): play_audio(txt)
