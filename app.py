import streamlit as st
import time
import google.generativeai as genai
import asyncio
import edge_tts
import speech_recognition as sr
from streamlit_mic_recorder import mic_recorder
from io import BytesIO
import re

# ===== Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© =====
st.set_page_config(page_title="Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ù…ØµØ±ÙŠ", page_icon="ğŸ‡ªğŸ‡¬", layout="centered")

# ===== ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù„ÙŠØµØ¨Ø­ ÙƒÙ„Ø§Ù…Ù‹Ø§ Ù…Ø³Ù…ÙˆØ¹Ù‹Ø§ =====
def prepare_text_for_audio(text):
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ² ØºÙŠØ± Ø§Ù„Ù…Ù†Ø·ÙˆÙ‚Ø©
    text = re.sub(r"[*#\"\n]", " ", text)

    # ØªÙ‚ØµÙŠØ± Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
    text = re.sub(r"\.{2,}", "ØŒ", text)

    # Ø¥Ø¬Ø¨Ø§Ø± ÙˆÙ‚ÙØ§Øª ØªÙ†ÙÙ‘Ø³ Ø·Ø¨ÙŠØ¹ÙŠØ©
    text = text.replace(".", "ØŒ ")
    text = text.replace("ØŒ", "ØŒ ")

    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ø²Ø§Ø¦Ø¯
    text = re.sub(r"(ØŒ\s*){2,}", "ØŒ ", text)

    return text.strip()

# ===== ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª =====
async def generate_speech(text, output_file, voice_code):
    clean_text = prepare_text_for_audio(text)
    communicate = edge_tts.Communicate(
        clean_text,
        voice_code,
        rate="-10%",
        pitch="+2Hz"
    )
    await communicate.save(output_file)

# ===== Ø§Ù„Ø¹Ù†ÙˆØ§Ù† =====
st.title("ğŸ™ï¸ Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ù…ØµØ±ÙŠ â€“ Ø´Ø±Ø­ Ø¹Ù„ÙˆÙ… Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")

# ===== ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± =====
password = st.text_input("ğŸ” Ø£Ø¯Ø®Ù„ ÙƒÙ„Ù…Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„", type="password")
if password != "SCIENCE60":
    st.warning("ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± ØºÙŠØ± ØµØ­ÙŠØ­Ø©")
    st.stop()

st.success("ØªÙ… Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¨Ù†Ø¬Ø§Ø­ âœ…")

# ===== Ø§Ù„Ù…Ø¤Ù‚Øª =====
if "start_time" not in st.session_state:
    st.session_state.start_time = time.time()

elapsed = time.time() - st.session_state.start_time
remaining = 3600 - elapsed

if remaining <= 0:
    st.error("â±ï¸ Ø§Ù†ØªÙ‡Øª Ù…Ø¯Ø© Ø§Ù„Ø¬Ù„Ø³Ø©")
    st.stop()

st.info(f"â³ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ: {int(remaining//60)} Ø¯Ù‚ÙŠÙ‚Ø©")

# ===== Ø¥Ø¹Ø¯Ø§Ø¯ Gemini =====
genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
model = genai.GenerativeModel("gemini-pro")

# ===== Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ØµÙˆØª =====
voice_options = {
    "Ù…ØµØ±ÙŠ â€“ Ø±Ø§Ø¬Ù„": "ar-EG-ShakirNeural",
    "Ù…ØµØ±ÙŠ â€“ Ø³Øª": "ar-EG-SalmaNeural"
}
selected_voice = st.selectbox("ğŸ§ Ø§Ø®ØªØ± ØµÙˆØª Ø§Ù„Ø´Ø±Ø­", list(voice_options.keys()))
selected_voice_code = voice_options[selected_voice]

# ===== ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ =====
audio = mic_recorder(start_prompt="ğŸ¤ Ø§Ø¶ØºØ· ÙˆØªÙƒÙ„Ù…", stop_prompt="â¹ï¸ ÙˆÙ‚Ù", key="recorder")

if audio:
    recognizer = sr.Recognizer()

    audio_data = sr.AudioData(
        audio["bytes"],
        sample_rate=audio["sample_rate"],
        sample_width=2
    )

    try:
        question = recognizer.recognize_google(audio_data, language="ar-EG")
        st.write(f"ğŸ—£ï¸ Ø³Ø¤Ø§Ù„Ùƒ: {question}")

        if st.button("ğŸ“© Ø£Ø¬Ø¨"):
            with st.spinner("ğŸ¤– Ø§Ù„Ù…Ø¹Ù„Ù… Ø¨ÙŠÙÙƒÙ‘Ø±..."):
                prompt = f"""
Ø§Ø´Ø±Ø­ Ù„Ø·Ø§Ù„Ø¨ Ø£ÙˆÙ„Ù‰ Ø«Ø§Ù†ÙˆÙŠ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ù…Ø¯Ø±Ø³ Ù…ØµØ±ÙŠ.
Ø§Ø³ØªØ®Ø¯Ù… Ø¬Ù…Ù„ Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ù‹Ø§.
Ø®Ù„ÙŠ Ø§Ù„Ø´Ø±Ø­ ÙƒØ£Ù†Ùƒ Ø¨ØªØªÙƒÙ„Ù… Ù…Ø´ Ø¨ØªÙƒØªØ¨.
Ø®Ø¯ Ù†ÙØ³ Ø¨ÙŠÙ† Ø§Ù„Ø¬Ù…Ù„.
Ù…Ø§ ØªØ³ØªØ®Ø¯Ù…Ø´ ÙØµØ­Ù‰ ØªÙ‚ÙŠÙ„Ø©.

Ø§Ù„Ø³Ø¤Ø§Ù„:
{question}
"""
                response = model.generate_content(prompt)

                st.markdown(f"### ğŸ“˜ Ø§Ù„Ø´Ø±Ø­:\n{response.text}")

                output_file = "response.mp3"
                asyncio.run(
                    generate_speech(
                        response.text,
                        output_file,
                        selected_voice_code
                    )
                )
                st.audio(output_file, format="audio/mp3", autoplay=True)

    except Exception as e:
        st.warning("âš ï¸ Ø§Ù„ØµÙˆØª Ù…Ø´ ÙˆØ§Ø¶Ø­ØŒ Ø¬Ø±Ù‘Ø¨ ØªØ§Ù†ÙŠ")

