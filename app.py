import streamlit as st

# âœ… ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø£ÙˆÙ„ Ø£Ù…Ø± Streamlit
st.set_page_config(page_title="Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ", layout="wide", page_icon="ğŸ“")

# =========================================================
# Imports + Availability checks (Ø¨Ø¯ÙˆÙ† Ø¥Ø³Ù‚Ø§Ø· Ø§Ù„ØªØ·Ø¨ÙŠÙ‚)
# =========================================================
import os
import time
import tempfile
import logging
import random
from contextlib import contextmanager
from typing import List, Optional, Tuple

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("smart_teacher")

# Google Gemini
try:
    import google.generativeai as genai
    GENAI_AVAILABLE = True
    GENAI_IMPORT_ERROR = ""
except Exception as e:
    GENAI_AVAILABLE = False
    GENAI_IMPORT_ERROR = str(e)

# Google Drive
try:
    from google.oauth2 import service_account
    from googleapiclient.discovery import build
    from googleapiclient.http import MediaIoBaseDownload
    DRIVE_AVAILABLE = True
    DRIVE_IMPORT_ERROR = ""
except Exception as e:
    DRIVE_AVAILABLE = False
    DRIVE_IMPORT_ERROR = str(e)

# Optional: mic recorder
try:
    from streamlit_mic_recorder import mic_recorder
    MIC_AVAILABLE = True
except Exception:
    MIC_AVAILABLE = False

# Optional: TTS
try:
    import edge_tts
    import asyncio
    TTS_AVAILABLE = True
except Exception:
    TTS_AVAILABLE = False


# =========================================================
# Streamlit cache compatibility (Ù„ØªÙØ§Ø¯ÙŠ Ø§Ø®ØªÙ„Ø§Ù Ø§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª)
# =========================================================
def _cache_resource(*dargs, **dkwargs):
    if hasattr(st, "cache_resource"):
        return st.cache_resource(*dargs, **dkwargs)
    if hasattr(st, "experimental_singleton"):
        return st.experimental_singleton(*dargs, **dkwargs)
    return st.cache(*dargs, **dkwargs)


def _cache_data(*dargs, **dkwargs):
    if hasattr(st, "cache_data"):
        return st.cache_data(*dargs, **dkwargs)
    if hasattr(st, "experimental_memo"):
        return st.experimental_memo(*dargs, **dkwargs)
    return st.cache(*dargs, **dkwargs)


# =========================================================
# CSS
# =========================================================
st.markdown(
    """
<style>
@import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;600;700&display=swap');
html, body, .stApp {
    font-family: 'Cairo', sans-serif !important;
    direction: rtl;
    text-align: right;
}
.header-box {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    padding: 1.2rem 1.5rem;
    border-radius: 15px;
    color: white;
    text-align: center;
    margin-bottom: 1rem;
}
.small-muted { color: #666; font-size: 0.9rem; }
.stButton > button {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border-radius: 10px;
    height: 46px;
    width: 100%;
    border: none;
    font-size: 16px;
}
</style>
""",
    unsafe_allow_html=True,
)

# =========================================================
# Constants
# =========================================================
FOLDER_ID = "1ub4ML8q4YCM_VZR991XXQ6hBBas2X6rS"

MAX_RETRIES = 4
BASE_RETRY_DELAY = 1.5
MAX_BACKOFF = 12

VOICE_NAME = "ar-EG-ShakirNeural"

STAGES = ["Ø§Ù„Ø§Ø¨ØªØ¯Ø§Ø¦ÙŠØ©", "Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ÙŠØ©", "Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©"]
GRADES = {
    "Ø§Ù„Ø§Ø¨ØªØ¯Ø§Ø¦ÙŠØ©": ["Ø§Ù„Ø±Ø§Ø¨Ø¹", "Ø§Ù„Ø®Ø§Ù…Ø³", "Ø§Ù„Ø³Ø§Ø¯Ø³"],
    "Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ÙŠØ©": ["Ø§Ù„Ø£ÙˆÙ„", "Ø§Ù„Ø«Ø§Ù†ÙŠ", "Ø§Ù„Ø«Ø§Ù„Ø«"],
    "Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©": ["Ø§Ù„Ø£ÙˆÙ„", "Ø§Ù„Ø«Ø§Ù†ÙŠ", "Ø§Ù„Ø«Ø§Ù„Ø«"],
}
TERMS = ["Ø§Ù„ØªØ±Ù… Ø§Ù„Ø£ÙˆÙ„", "Ø§Ù„ØªØ±Ù… Ø§Ù„Ø«Ø§Ù†ÙŠ"]

GRADE_MAP = {
    "Ø§Ù„Ø±Ø§Ø¨Ø¹": "4",
    "Ø§Ù„Ø®Ø§Ù…Ø³": "5",
    "Ø§Ù„Ø³Ø§Ø¯Ø³": "6",
    "Ø§Ù„Ø£ÙˆÙ„": "1",
    "Ø§Ù„Ø«Ø§Ù†ÙŠ": "2",
    "Ø§Ù„Ø«Ø§Ù„Ø«": "3",
}
SUBJECT_MAP = {"ÙƒÙŠÙ…ÙŠØ§Ø¡": "Chem", "ÙÙŠØ²ÙŠØ§Ø¡": "Physics", "Ø£Ø­ÙŠØ§Ø¡": "Biology"}

# =========================================================
# Helpers
# =========================================================
@contextmanager
def status_box(label: str):
    """ÙŠØ¯Ø¹Ù… st.status Ù„Ùˆ Ù…ÙˆØ¬ÙˆØ¯Ø© ÙˆØ¥Ù„Ø§ fallback Ø¥Ù„Ù‰ spinner."""
    if hasattr(st, "status"):
        with st.status(label, expanded=True) as s:
            yield s
    else:
        with st.spinner(label):
            yield None


def subjects_for(stage: str, grade: str) -> List[str]:
    if stage in ["Ø§Ù„Ø§Ø¨ØªØ¯Ø§Ø¦ÙŠØ©", "Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ÙŠØ©"]:
        return ["Ø¹Ù„ÙˆÙ…"]
    if stage == "Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©":
        if grade == "Ø§Ù„Ø£ÙˆÙ„":
            return ["Ø¹Ù„ÙˆÙ… Ù…ØªÙƒØ§Ù…Ù„Ø©"]
        return ["ÙƒÙŠÙ…ÙŠØ§Ø¡", "ÙÙŠØ²ÙŠØ§Ø¡", "Ø£Ø­ÙŠØ§Ø¡"]
    return ["Ø¹Ù„ÙˆÙ…"]


def generate_file_name_search(stage: str, grade: str, subject: str, lang_type: str) -> str:
    g_num = GRADE_MAP.get(grade, "1")
    lang_code = "En" if lang_type == "English" else "Ar"

    if stage == "Ø§Ù„Ø§Ø¨ØªØ¯Ø§Ø¦ÙŠØ©":
        return f"Grade{g_num}_{lang_code}"
    if stage == "Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ÙŠØ©":
        return f"Prep{g_num}_{lang_code}"
    if stage == "Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©":
        if grade == "Ø§Ù„Ø£ÙˆÙ„":
            return f"Sec1_Integrated_{lang_code}"
        sub_code = SUBJECT_MAP.get(subject, "Chem")
        return f"Sec{g_num}_{sub_code}_{lang_code}"
    return ""


def get_api_keys() -> List[str]:
    """Ù‚Ø±Ø§Ø¡Ø© GOOGLE_API_KEYS Ù…Ù† secrets (ÙŠØ¯Ø¹Ù… list Ø£Ùˆ string Ù…ÙØµÙˆÙ„ Ø¨ÙÙˆØ§ØµÙ„)."""
    try:
        keys = st.secrets.get("GOOGLE_API_KEYS", [])
        if isinstance(keys, str):
            return [k.strip() for k in keys.split(",") if k.strip()]
        if isinstance(keys, (list, tuple)):
            return [str(k).strip() for k in keys if str(k).strip()]
        return []
    except Exception as e:
        logger.error(f"Failed to read GOOGLE_API_KEYS: {e}")
        return []


GOOGLE_API_KEYS = get_api_keys()


def configure_genai_by_key(key: str) -> bool:
    if not GENAI_AVAILABLE:
        return False
    try:
        genai.configure(api_key=key)
        return True
    except Exception as e:
        logger.error(f"genai.configure failed: {e}")
        return False


def normalize_model_name(name: str) -> str:
    """list_models Ù‚Ø¯ ÙŠØ±Ø¬Ù‘Ø¹ models/xxx. Ù†Ø·Ø¨Ù‘Ø¹Ù‡Ø§ Ù„Ù„Ø£Ù…Ø§Ù†."""
    if not name:
        return name
    return name.split("/", 1)[1] if name.startswith("models/") else name


# =========================================================
# Google Drive (Service + Search + Download)
# =========================================================
@_cache_resource(show_spinner=False)
def get_drive_service_cached():
    if not DRIVE_AVAILABLE:
        return None
    try:
        if "gcp_service_account" not in st.secrets:
            return None

        creds_dict = dict(st.secrets["gcp_service_account"])
        if "private_key" in creds_dict and isinstance(creds_dict["private_key"], str):
            creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")

        credentials = service_account.Credentials.from_service_account_info(
            creds_dict,
            scopes=["https://www.googleapis.com/auth/drive.readonly"],
        )
        return build("drive", "v3", credentials=credentials, cache_discovery=False)
    except Exception as e:
        logger.error(f"Drive service build error: {e}")
        return None


def find_best_drive_file(service, search_name: str):
    query = (
        f"'{FOLDER_ID}' in parents and "
        f"name contains '{search_name}' and "
        f"mimeType='application/pdf' and trashed=false"
    )

    results = service.files().list(
        q=query,
        fields="files(id, name, size, modifiedTime, mimeType)",
        pageSize=20,
    ).execute()

    files = results.get("files", [])
    if not files:
        return None

    def to_int(x):
        try:
            return int(x)
        except Exception:
            return 0

    files.sort(key=lambda f: to_int(f.get("size", 0)), reverse=True)
    return files[0]


def download_drive_file(service, file_id: str) -> str:
    request = service.files().get_media(fileId=file_id)

    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".pdf")
    tmp_path = tmp.name
    downloader = MediaIoBaseDownload(tmp, request)
    done = False

    try:
        while not done:
            _, done = downloader.next_chunk()
        tmp.close()

        if os.path.getsize(tmp_path) < 1500:
            os.unlink(tmp_path)
            raise RuntimeError("Ø§Ù„Ù…Ù„Ù ØªÙ… ØªÙ†Ø²ÙŠÙ„Ù‡ Ù„ÙƒÙ†Ù‡ ÙØ§Ø±Øº/ØµØºÙŠØ± Ø¬Ø¯Ù‹Ø§.")
        return tmp_path
    except Exception:
        try:
            tmp.close()
        except Exception:
            pass
        if os.path.exists(tmp_path):
            os.unlink(tmp_path)
        raise


def find_and_download_book(search_name: str) -> Tuple[Optional[str], str]:
    service = get_drive_service_cached()
    if not service:
        return None, "ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Google Drive (ØªØ£ÙƒØ¯ Ù…Ù† Service Account ÙÙŠ secrets)."

    try:
        target = find_best_drive_file(service, search_name)
        if not target:
            return None, f"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ù…Ø·Ø§Ø¨Ù‚: {search_name}"

        local_path = download_drive_file(service, target["id"])
        return local_path, target["name"]
    except Exception as e:
        logger.error(f"Drive download error: {e}")
        return None, str(e)


# =========================================================
# Gemini (Dynamic models + Upload + Chat)
# =========================================================
@_cache_data(ttl=3600, show_spinner=False)
def list_generate_models_for_key(api_key: str) -> List[str]:
    """
    ÙŠØ±Ø¬Ø¹ Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ù‡Ø°Ø§ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„ØªÙŠ ØªØ¯Ø¹Ù… generateContent.
    Ù…Ù‡Ù…: ÙŠÙ…Ù†Ø¹ 404 Ù…Ø«Ù„ gemini-pro ØºÙŠØ± Ø§Ù„Ù…ØªØ§Ø­.
    """
    if not GENAI_AVAILABLE:
        return []

    genai.configure(api_key=api_key)

    # Ù„Ùˆ list_models ØºÙŠØ± Ù…ØªØ§Ø­Ø© ÙÙŠ Ø¥ØµØ¯Ø§Ø± Ù‚Ø¯ÙŠÙ…
    if not hasattr(genai, "list_models"):
        # fallback Ø¨Ø¯ÙˆÙ† gemini-pro
        return ["gemini-2.0-flash", "gemini-1.5-flash", "gemini-1.5-pro"]

    models = []
    for m in genai.list_models():
        name = getattr(m, "name", "")
        methods = getattr(m, "supported_generation_methods", []) or []
        if name and ("generateContent" in methods):
            models.append(name)

    preferred = [
        "models/gemini-2.0-flash",
        "models/gemini-2.0-flash-lite",
        "models/gemini-1.5-flash",
        "models/gemini-1.5-pro",
    ]

    ordered = []
    for p in preferred:
        if p in models:
            ordered.append(p)
    for x in models:
        if x not in ordered:
            ordered.append(x)

    return ordered


def upload_to_gemini(local_path: str, api_key: str):
    if not configure_genai_by_key(api_key):
        return None
    try:
        gemini_file = genai.upload_file(local_path, mime_type="application/pdf")

        waited = 0
        while getattr(gemini_file, "state", None) and gemini_file.state.name == "PROCESSING" and waited < 90:
            time.sleep(2)
            waited += 2
            gemini_file = genai.get_file(gemini_file.name)

        if getattr(gemini_file, "state", None) and gemini_file.state.name == "FAILED":
            return None

        return gemini_file
    except Exception as e:
        logger.error(f"Gemini upload error: {e}")
        return None


def create_chat_session(gemini_file):
    if not GENAI_AVAILABLE:
        st.error(f"Ù…ÙƒØªØ¨Ø© google-generativeai ØºÙŠØ± Ù…ØªØ§Ø­Ø©: {GENAI_IMPORT_ERROR}")
        return None
    if not GOOGLE_API_KEYS:
        st.error("Ù„Ø§ ØªÙˆØ¬Ø¯ GOOGLE_API_KEYS Ø¯Ø§Ø®Ù„ secrets.")
        return None

    system_prompt = """
Ø£Ù†Øª Ù…ÙØ¹Ù„Ù‘Ù… Ù…ØµØ±ÙŠ Ø®Ø¨ÙŠØ±.
Ø§Ø´Ø±Ø­ ÙˆØ£Ø¬Ø¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„Ù…Ø±ÙÙ‚ ÙÙ‚Ø·.
Ù‚ÙˆØ§Ø¹Ø¯ Ø¥Ù„Ø²Ø§Ù…ÙŠØ©:
- Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø®Ø§Ø±Ø¬ Ø§Ù„ÙƒØªØ§Ø¨.
- Ù„Ùˆ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„ÙƒØªØ§Ø¨: Ù‚Ù„ "Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© Ø¯ÙŠ Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„Ù…Ø±ÙÙ‚".
- Ø®Ù„ÙŠ Ø§Ù„Ø´Ø±Ø­ Ù…Ù†Ø¸Ù… ÙˆØ¨Ø³ÙŠØ· Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ©.
"""

    last_error = None

    for key in GOOGLE_API_KEYS:
        try:
            genai.configure(api_key=key)
            candidates = list_generate_models_for_key(key)
            if not candidates:
                last_error = "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…ÙˆØ¯ÙŠÙ„Ø§Øª ØªØ¯Ø¹Ù… generateContent Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…ÙØªØ§Ø­."
                continue

            for m in candidates:
                try:
                    model_name = normalize_model_name(m)
                    model = genai.GenerativeModel(
                        model_name=model_name,
                        system_instruction=system_prompt,
                        generation_config={"temperature": 0.2, "top_p": 0.9, "max_output_tokens": 1024},
                    )
                    chat = model.start_chat(history=[])
                    chat.send_message([gemini_file, "ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒØªØ§Ø¨. Ø§Ù„ØªØ²Ù… Ø¨Ø´Ø±Ø­Ù‡ ÙÙ‚Ø·."])
                    return chat
                except Exception as e:
                    last_error = e
                    continue

        except Exception as e:
            last_error = e
            continue

    st.error(f"ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ 
