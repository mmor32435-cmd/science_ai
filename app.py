import streamlit as st
import nest_asyncio
import threading
import time
from io import BytesIO
from datetime import datetime

# Ù…ÙƒØªØ¨Ø§Øª Google ÙˆØ§Ù„ÙˆØ³Ø§Ø¦Ø·
import google.generativeai as genai
import edge_tts
import speech_recognition as sr
from streamlit_mic_recorder import mic_recorder
from PIL import Image
from google.oauth2 import service_account
import gspread
import asyncio

# 1. ØªÙØ¹ÙŠÙ„ Ø§Ù„ØªØ²Ø§Ù…Ù† ÙˆØ¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
nest_asyncio.apply()
st.set_page_config(page_title="Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ", layout="wide")

# 2. Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹ (Ø¥Ø¬Ø¨Ø§Ø± Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„ÙØ§ØªØ­)
st.markdown("""
<style>
    /* Ø¥Ø¬Ø¨Ø§Ø± Ø§Ù„Ø®Ù„ÙÙŠØ© Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡ ÙˆØ§Ù„Ù†Øµ Ø§Ù„Ø£Ø³ÙˆØ¯ */
    [data-testid="stAppViewContainer"] {
        background-color: #ffffff;
    }
    [data-testid="stHeader"] {
        background-color: #ffffff;
    }
    [data-testid="stSidebar"] {
        background-color: #f0f2f6;
    }
    /* Ø¬Ø¹Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØµÙˆØµ Ø³ÙˆØ¯Ø§Ø¡ */
    h1, h2, h3, p, span, div, label {
        color: #000000 !important;
    }
    /* ØªÙ†Ø³ÙŠÙ‚ Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø´Ø§Øª */
    .stChatMessage {
        background-color: #f9f9f9;
        border-radius: 10px;
        padding: 10px;
        margin-bottom: 10px;
        border: 1px solid #ddd;
    }
</style>
""", unsafe_allow_html=True)

# 3. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¬Ù„Ø³Ø©
if "auth" not in st.session_state:
    st.session_state.auth = False
    st.session_state.user = ""
    st.session_state.msgs = []

# 4. Ø¯ÙˆØ§Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ (ØªÙ… ØªØ¨Ø³ÙŠØ·Ù‡Ø§)
def get_db():
    if "gcp_service_account" not in st.secrets: return None
    try:
        cred = service_account.Credentials.from_service_account_info(
            dict(st.secrets["gcp_service_account"]),
            scopes=['https://www.googleapis.com/auth/spreadsheets']
        )
        return gspread.authorize(cred)
    except: return None

def get_student_pass():
    client = get_db()
    if not client: return None
    try:
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø®Ù„ÙŠØ© B1 Ù…Ù† Ø´ÙŠØª App_Control
        val = client.open("App_Control").sheet1.acell('B1').value
        return str(val).strip() if val else None
    except: return None

def get_ai():
    keys = st.secrets.get("GOOGLE_API_KEYS", [])
    if not keys: return None
    import random
    genai.configure(api_key=random.choice(keys))
    # Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù‚Ø¯ÙŠÙ… Ù„Ø£Ù†Ù‡ Ø§Ù„Ø£Ø¶Ù…Ù†
    return genai.GenerativeModel('gemini-pro')

def get_vision_ai():
    keys = st.secrets.get("GOOGLE_API_KEYS", [])
    if not keys: return None
    import random
    genai.configure(api_key=random.choice(keys))
    return genai.GenerativeModel('gemini-pro-vision')

# Ø¯ÙˆØ§Ù„ Ø§Ù„ØµÙˆØª
async def tts_gen(text):
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ² Ù‚Ø¨Ù„ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©
    text = text.replace("*", "").replace("#", "")
    cm = edge_tts.Communicate(text, "ar-EG-ShakirNeural")
    out = BytesIO()
    async for ch in cm.stream():
        if ch["type"] == "audio": out.write(ch["data"])
    return out

def play_audio(txt):
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        aud = loop.run_until_complete(tts_gen(txt[:200]))
        st.audio(aud, format='audio/mp3', autoplay=True)
    except: pass

# ============================
# Ø§Ù„Ø´Ø§Ø´Ø© 1: ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„
# ============================
if not st.session_state.auth:
    c1, c2, c3 = st.columns([1,2,1])
    with c2:
        st.title("ğŸ” ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„")
        with st.form("login_form"):
            name = st.text_input("Ø§Ù„Ø§Ø³Ù…:")
            code = st.text_input("Ø§Ù„ÙƒÙˆØ¯:", type="password")
            btn = st.form_submit_button("Ø¯Ø®ÙˆÙ„")
            
            if btn:
                real_pass = get_student_pass()
                # ÙƒÙˆØ¯ Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø«Ø§Ø¨Øª
                is_admin = (code == "ADMIN_2024")
                # ÙƒÙˆØ¯ Ø§Ù„Ø·Ø§Ù„Ø¨ Ù…Ù† Ø§Ù„Ø´ÙŠØª
                is_student = (real_pass and code == real_pass)
                
                if is_admin or is_student:
                    st.session_state.auth = True
                    st.session_state.user = name
                    st.success("ØªÙ… Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¨Ù†Ø¬Ø§Ø­")
                    st.rerun()
                else:
                    st.error("Ø§Ù„ÙƒÙˆØ¯ ØºÙŠØ± ØµØ­ÙŠØ­ Ø£Ùˆ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø§ØªØµØ§Ù„")
    st.stop()

# ============================
# Ø§Ù„Ø´Ø§Ø´Ø© 2: Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
# ============================
st.sidebar.title(f"Ù…Ø±Ø­Ø¨Ø§Ù‹ {st.session_state.user}")
if st.sidebar.button("Ø®Ø±ÙˆØ¬"):
    st.session_state.auth = False
    st.rerun()

st.title("ğŸ§¬ Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ")

# Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª (Ø£Ø¯ÙˆØ§Øª)
t1, t2, t3 = st.tabs(["ğŸ™ï¸ ØµÙˆØª", "ğŸ“ ÙƒØªØ§Ø¨Ø©", "ğŸ“· ØµÙˆØ±Ø©"])

with t1:
    st.write("ØªØ­Ø¯Ø« Ø§Ù„Ø¢Ù†:")
    audio = mic_recorder(start_prompt="ğŸ¤ Ø§Ø¨Ø¯Ø£", stop_prompt="â¹ï¸ Ø¥Ø±Ø³Ø§Ù„")
    
    if audio:
        try:
            r = sr.Recognizer()
            audio_data = BytesIO(audio['bytes'])
            with sr.AudioFile(audio_data) as source:
                r.adjust_for_ambient_noise(source)
                voice = r.record(source)
                txt = r.recognize_google(voice, language="ar-EG")
                
            st.success(f"Ø³Ù…Ø¹Øª: {txt}")
            
            # Ø¥Ø±Ø³Ø§Ù„ Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
            m = get_ai()
            if m:
                reply = m.generate_content(f"Ø±Ø¯ Ø¨Ø§Ø®ØªØµØ§Ø±: {txt}").text
                st.session_state.msgs.append({"role": "user", "txt": txt})
                st.session_state.msgs.append({"role": "ai", "txt": reply})
                st.rerun()
        except:
            st.error("Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ÙÙ‡Ù… Ø§Ù„ØµÙˆØªØŒ Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰")

with t2:
    q = st.text_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ:")
    if st.button("Ø¥Ø±Ø³Ø§Ù„") and q:
        m = get_ai()
        if m:
            reply = m.generate_content(f"Ø§Ø´Ø±Ø­: {q}").text
            st.session_state.msgs.append({"role": "user", "txt": q})
            st.session_state.msgs.append({"role": "ai", "txt": reply})
            st.rerun()

with t3:
    up = st.file_uploader("ØµÙˆØ±Ø©", type=['png','jpg'])
    if up and st.button("ØªØ­Ù„ÙŠÙ„"):
        img = Image.open(up)
        st.image(img, width=200)
        m = get_vision_ai()
        if m:
            reply = m.generate_content(["Ø§Ø´Ø±Ø­ Ø§Ù„ØµÙˆØ±Ø©", img]).text
            st.session_state.msgs.append({"role": "user", "txt": "Ù‚Ø§Ù… Ø¨Ø±ÙØ¹ ØµÙˆØ±Ø©"})
            st.session_state.msgs.append({"role": "ai", "txt": reply})
            st.rerun()

# Ø¹Ø±Ø¶ Ø§Ù„Ø³Ø¬Ù„ (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒÙˆÙ†Ø§Øª Streamlit Ø§Ù„Ø£ØµÙ„ÙŠØ©)
st.divider()
st.subheader("Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©")

# Ù†Ø¹ÙƒØ³ Ø§Ù„ØªØ±ØªÙŠØ¨ Ù„Ù†Ø±Ù‰ Ø§Ù„Ø£Ø­Ø¯Ø« Ø£ÙˆÙ„Ø§Ù‹
for msg in reversed(st.session_state.msgs):
    role = msg["role"]
    txt = msg["txt"]
    
    if role == "user":
        with st.chat_message("user"):
            st.write(txt)
    else:
        with st.chat_message("assistant"):
            st.write(txt)
            # Ø²Ø± ØµÙˆØª ÙØ±ÙŠØ¯
            key = f"btn_{hash(txt)}"
            if st.button("ğŸ”Š Ø§Ø³ØªÙ…Ø¹", key=key):
                play_audio(txt)
