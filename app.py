import streamlit as st
import nest_asyncio
import threading
import os
import google.generativeai as genai
import edge_tts
import speech_recognition as sr
from streamlit_mic_recorder import mic_recorder
from PIL import Image
from google.oauth2 import service_account
import gspread
import asyncio

# ØªÙØ¹ÙŠÙ„ Ø§Ù„ØªØ²Ø§Ù…Ù†
nest_asyncio.apply()

# 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ", layout="wide")

# ØªØµÙ…ÙŠÙ… ÙŠØ¬Ø¨Ø± Ø§Ù„Ù†ØµÙˆØµ Ø¹Ù„Ù‰ Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ø£Ø³ÙˆØ¯ ÙˆØ§Ù„Ø®Ù„ÙÙŠØ© Ø¨ÙŠØ¶Ø§Ø¡
st.markdown("""
<style>
    /* Ø¥Ø¬Ø¨Ø§Ø± Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„ÙØ§ØªØ­ */
    [data-testid="stAppViewContainer"] { background-color: #ffffff; }
    [data-testid="stSidebar"] { background-color: #f0f2f6; }
    [data-testid="stHeader"] { background-color: #ffffff; }
    
    /* Ø§Ù„Ù†ØµÙˆØµ Ø³ÙˆØ¯Ø§Ø¡ */
    h1, h2, h3, p, div, span, label { color: #000000 !important; }
    
    /* Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø´Ø§Øª */
    .stChatMessage { background-color: #f8f9fa; border: 1px solid #ddd; }
    
    /* Ø§Ù„Ø£Ø²Ø±Ø§Ø± */
    .stButton>button { width: 100%; border-radius: 8px; }
</style>
""", unsafe_allow_html=True)

# 2. ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
if "auth" not in st.session_state:
    st.session_state.auth = False
    st.session_state.user = ""
    st.session_state.grade = ""
    st.session_state.msgs = []

# 3. Ø¯ÙˆØ§Ù„ Ø§Ù„Ù†Ø¸Ø§Ù…
def get_db_pass():
    if "gcp_service_account" not in st.secrets: return None
    try:
        cred = service_account.Credentials.from_service_account_info(
            dict(st.secrets["gcp_service_account"]),
            scopes=['https://www.googleapis.com/auth/spreadsheets']
        )
        client = gspread.authorize(cred)
        # Ø¬Ù„Ø¨ Ø§Ù„Ù‚ÙŠÙ…Ø© ÙˆØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª
        val = client.open("App_Control").sheet1.acell('B1').value
        return str(val).strip() if val else None
    except: return None

def get_ai():
    keys = st.secrets.get("GOOGLE_API_KEYS", [])
    if not keys: return None
    import random
    genai.configure(api_key=random.choice(keys))
    return genai.GenerativeModel('gemini-pro')

def get_vision_ai():
    keys = st.secrets.get("GOOGLE_API_KEYS", [])
    if not keys: return None
    import random
    genai.configure(api_key=random.choice(keys))
    return genai.GenerativeModel('gemini-pro-vision')

# 4. Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† (Ø§Ù„Ø­ÙØ¸ ÙÙŠ Ù…Ù„Ù Ù…Ø¤Ù‚Øª)
def transribe_audio(audio_bytes):
    r = sr.Recognizer()
    try:
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ù…Ø¤Ù‚ØªØ§Ù‹ Ù„Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©
        with open("temp_audio.wav", "wb") as f:
            f.write(audio_bytes)
        
        with sr.AudioFile("temp_audio.wav") as source:
            r.adjust_for_ambient_noise(source)
            audio = r.record(source)
            # Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…
            text = r.recognize_google(audio, language="ar-EG")
            return text
    except Exception as e:
        return None

# ============================
# Ø´Ø§Ø´Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„
# ============================
if not st.session_state.auth:
    col1, col2, col3 = st.columns([1,2,1])
    with col2:
        st.title("ğŸ” ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„")
        with st.form("login_form"):
            name = st.text_input("Ø§Ù„Ø§Ø³Ù…:")
            # Ø¥Ø¹Ø§Ø¯Ø© Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØµÙÙˆÙ
            grade = st.selectbox("Ø§Ù„ØµÙ:", ["Ø§Ù„Ø±Ø§Ø¨Ø¹", "Ø§Ù„Ø®Ø§Ù…Ø³", "Ø§Ù„Ø³Ø§Ø¯Ø³", "Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ÙŠ", "Ø§Ù„Ø«Ø§Ù†ÙˆÙŠ"])
            code = st.text_input("Ø§Ù„ÙƒÙˆØ¯:", type="password")
            
            if st.form_submit_button("Ø¯Ø®ÙˆÙ„"):
                real_pass = get_db_pass()
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ø¹ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
                user_code = code.strip()
                
                is_admin = (user_code == "ADMIN_2024")
                is_student = (real_pass and user_code == real_pass)
                
                if is_admin or is_student:
                    st.session_state.auth = True
                    st.session_state.user = name
                    st.session_state.grade = grade
                    st.rerun()
                else:
                    st.error("Ø§Ù„ÙƒÙˆØ¯ ØºÙŠØ± ØµØ­ÙŠØ­ (ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø´ÙŠØª)")
    st.stop()

# ============================
# Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
# ============================
with st.sidebar:
    st.header(f"Ø§Ù„Ø·Ø§Ù„Ø¨: {st.session_state.user}")
    st.info(f"Ø§Ù„ØµÙ: {st.session_state.grade}")
    if st.button("Ø®Ø±ÙˆØ¬"):
        st.session_state.auth = False
        st.rerun()

st.title("ğŸ§¬ Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ")

# Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª
tab1, tab2, tab3 = st.tabs(["ğŸ™ï¸ ØªØ­Ø¯Ø«", "âœï¸ Ø§ÙƒØªØ¨", "ğŸ“¸ ØµÙˆØ±"])

# 1. ØªØ¨ÙˆÙŠØ¨ Ø§Ù„ØµÙˆØª (Ø§Ù„Ù…ØµÙ„Ø­)
with tab1:
    st.write("Ø§Ø¶ØºØ· ÙˆØ³Ø¬Ù„ Ø³Ø¤Ø§Ù„Ùƒ:")
    audio = mic_recorder(start_prompt="ğŸ¤ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ³Ø¬ÙŠÙ„", stop_prompt="â¹ï¸ Ø¥Ù†Ù‡Ø§Ø¡", key='mic')
    
    if audio:
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª..."):
            text = transribe_audio(audio['bytes'])
            if text:
                st.success(f"Ø³Ù…Ø¹ØªÙƒ ØªÙ‚ÙˆÙ„: {text}")
                # Ø§Ù„Ø±Ø¯
                m = get_ai()
                if m:
                    res = m.generate_content(f"Ø£Ø¬Ø¨ Ø¨Ø§Ø®ØªØµØ§Ø±: {text}").text
                    st.session_state.msgs.append({"role": "user", "content": text})
                    st.session_state.msgs.append({"role": "ai", "content": res})
                    st.rerun() # ØªØ­Ø¯ÙŠØ« ÙÙˆØ±ÙŠ
            else:
                st.error("Ù„Ù… Ø£Ø³Ù…Ø¹ Ø¬ÙŠØ¯Ø§Ù‹ØŒ Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")

# 2. ØªØ¨ÙˆÙŠØ¨ Ø§Ù„ÙƒØªØ§Ø¨Ø©
with tab2:
    q = st.text_area("Ø³Ø¤Ø§Ù„Ùƒ:", height=70)
    if st.button("Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„"):
        if q:
            m = get_ai()
            if m:
                prompt = f"Ø§Ø´Ø±Ø­ Ù„Ø·Ø§Ù„Ø¨ ÙÙŠ {st.session_state.grade}: {q}"
                res = m.generate_content(prompt).text
                st.session_state.msgs.append({"role": "user", "content": q})
                st.session_state.msgs.append({"role": "ai", "content": res})
                st.rerun()

# 3. ØªØ¨ÙˆÙŠØ¨ Ø§Ù„ØµÙˆØ±
with tab3:
    up = st.file_uploader("ØµÙˆØ±Ø©", type=['jpg','png'])
    if up and st.button("ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©"):
        img = Image.open(up)
        st.image(img, width=200)
        m = get_vision_ai()
        if m:
            res = m.generate_content(["Ø§Ø´Ø±Ø­ Ø§Ù„ØµÙˆØ±Ø© Ø¹Ù„Ù…ÙŠØ§Ù‹", img]).text
            st.session_state.msgs.append({"role": "user", "content": "Ø£Ø±Ø³Ù„ ØµÙˆØ±Ø©"})
            st.session_state.msgs.append({"role": "ai", "content": res})
            st.rerun()

# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (Ø§Ù„Ø£Ø³ÙÙ„)
st.divider()
for msg in reversed(st.session_state.msgs):
    role = msg["role"]
    content = msg["content"]
    
    if role == "user":
        with st.chat_message("user"):
            st.write(content)
    else:
        with st.chat_message("assistant"):
            st.write(content)
            
            # Ø²Ø± Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØª (Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯)
            if st.button("ğŸ”Š Ù‚Ø±Ø§Ø¡Ø©", key=str(hash(content))):
                async def play():
                    cm = edge_tts.Communicate(content[:200], "ar-EG-ShakirNeural")
                    out = b""
                    async for chunk in cm.stream():
                        if chunk["type"] == "audio": out += chunk["data"]
                    st.audio(out, format='audio/mp3')
                asyncio.run(play())
