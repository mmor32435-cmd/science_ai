import streamlit as st
from google.oauth2 import service_account
import google.generativeai as genai
import gspread
from PIL import Image
import random
import speech_recognition as sr
from streamlit_mic_recorder import mic_recorder
import asyncio
import edge_tts
import tempfile
import os

# ==========================================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
# ==========================================
st.set_page_config(
    page_title="Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø¹Ù„Ù…ÙŠ | Ø§Ù„Ø³ÙŠØ¯ Ø§Ù„Ø¨Ø¯ÙˆÙŠ",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==========================================
# 2. Ø§Ù„ØªØµÙ…ÙŠÙ… Ø¹Ø§Ù„ÙŠ Ø§Ù„ØªØ¨Ø§ÙŠÙ† (High Contrast CSS)
# ==========================================
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
    
    html, body, [class*="css"] {
        font-family: 'Cairo', sans-serif;
        direction: rtl;
        text-align: right;
        color: #000000 !important; /* ÙØ±Ø¶ Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ø£Ø³ÙˆØ¯ Ù„Ù„Ù†ØµÙˆØµ */
    }
    
    /* Ø®Ù„ÙÙŠØ© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ */
    .stApp {
        background-color: #f0f2f6;
    }
    
    /* ØµÙ†Ø¯ÙˆÙ‚ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† */
    .header-box {
        background: linear-gradient(135deg, #004e92 0%, #000428 100%);
        padding: 2rem;
        border-radius: 15px;
        color: #ffffff !important; /* Ù†Øµ Ø£Ø¨ÙŠØ¶ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙÙ‚Ø· */
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 4px 10px rgba(0,0,0,0.2);
    }
    .header-box h1, .header-box h3 { color: #ffffff !important; }

    /* ØªØ­Ø³ÙŠÙ† ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ø´Ø§Øª Ù„ØªÙƒÙˆÙ† ÙˆØ§Ø¶Ø­Ø© */
    .stChatMessage {
        background-color: #ffffff;
        border: 1px solid #ddd;
        border-radius: 10px;
        color: #000000 !important;
    }
    
    /* Ø§Ù„Ø£Ø²Ø±Ø§Ø± */
    .stButton>button {
        background-color: #004e92;
        color: white !important;
        border-radius: 8px;
        height: 50px;
        width: 100%;
        font-weight: bold;
        font-size: 18px;
    }
    .stButton>button:hover { background-color: #003366; }

    /* Ø§Ù„Ù†ØµÙˆØµ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø­Ù‚ÙˆÙ„ */
    .stTextInput input, .stSelectbox div, .stTextArea textarea {
        color: #000000 !important;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

st.markdown("""
<div class="header-box">
    <h1>Ø§Ù„Ø£Ø³ØªØ§Ø° / Ø§Ù„Ø³ÙŠØ¯ Ø§Ù„Ø¨Ø¯ÙˆÙŠ</h1>
    <h3>Mr. Elsayed Elbadawy - Expert Science Tutor</h3>
</div>
""", unsafe_allow_html=True)

# ==========================================
# 3. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¬Ù„Ø³Ø©
# ==========================================
if 'user_data' not in st.session_state:
    st.session_state.user_data = {
        "logged_in": False, "role": None, "name": "", "grade": "", "stage": "", "lang": ""
    }
if 'messages' not in st.session_state: st.session_state.messages = []

# ==========================================
# 4. Ø¯ÙˆØ§Ù„ Ø§Ù„Ø§ØªØµØ§Ù„
# ==========================================
TEACHER_KEY = st.secrets.get("TEACHER_MASTER_KEY", "ADMIN")
SHEET_NAME = st.secrets.get("CONTROL_SHEET_NAME", "App_Control")

@st.cache_resource
def get_gspread_client():
    if "gcp_service_account" not in st.secrets: return None
    try:
        creds_dict = dict(st.secrets["gcp_service_account"])
        if "private_key" in creds_dict:
            creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
        scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
        creds = service_account.Credentials.from_service_account_info(creds_dict, scopes=scopes)
        return gspread.authorize(creds)
    except: return None

def check_student_code(input_code):
    client = get_gspread_client()
    if not client: return False
    try:
        sh = client.open(SHEET_NAME)
        real_code = str(sh.sheet1.acell("B1").value).strip()
        return str(input_code).strip() == real_code
    except: return False

# ==========================================
# 5. ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„ØµÙˆØª ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ (The Brain)
# ==========================================

# ğŸ¤ Ø¯Ø§Ù„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ù„Ù†Øµ (ØªÙ… Ø¥ØµÙ„Ø§Ø­Ù‡Ø§ Ø¨Ù…Ù„Ù Ù…Ø¤Ù‚Øª)
def speech_to_text(audio_bytes):
    r = sr.Recognizer()
    try:
        # Ø­ÙØ¸ Ø§Ù„ØµÙˆØª ÙÙŠ Ù…Ù„Ù Ù…Ø¤Ù‚Øª Ù„ÙŠØªÙ…ÙƒÙ† Google Recognizer Ù…Ù† Ù‚Ø±Ø§Ø¡ØªÙ‡
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(audio_bytes)
            tmp_filename = tmp_file.name
        
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
        with sr.AudioFile(tmp_filename) as source:
            audio_data = r.record(source)
            # Ø§Ù„ØªØ¹Ø±Ù (ÙŠØ¯Ø¹Ù… Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ© ÙˆØ§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© ÙˆØ§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰)
            text = r.recognize_google(audio_data, language="ar-EG")
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„Ù
        os.remove(tmp_filename)
        return text
    except Exception:
        return None

# ğŸ”Š Ø¯Ø§Ù„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ù„ØµÙˆØª (Ø¨Ø´Ø±ÙŠ ÙˆØ§Ø­ØªØ±Ø§ÙÙŠ)
async def generate_speech_async(text, voice="ar-EG-SalmaNeural"):
    communicate = edge_tts.Communicate(text, voice)
    # Ø­ÙØ¸ ÙÙŠ Ù…Ù„Ù Ù…Ø¤Ù‚Øª
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
        await communicate.save(tmp_file.name)
        return tmp_file.name

def text_to_speech_pro(text):
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù„Ø§Ù…ØªØ²Ø§Ù…Ù†Ø©
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        file_path = loop.run_until_complete(generate_speech_async(text))
        return file_path
    except Exception:
        return None

# ğŸ§  Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
def get_best_model():
    try:
        models = genai.list_models()
        chat_models = [m.name for m in models if 'generateContent' in m.supported_generation_methods]
        if not chat_models: return 'models/gemini-1.5-flash'
        for m in chat_models:
            if 'flash' in m.lower(): return m
        return chat_models[0]
    except: return 'models/gemini-1.5-flash'

def get_ai_response(user_text, img_obj=None):
    try:
        keys = st.secrets.get("GOOGLE_API_KEYS", [])
        if not keys: return "âš ï¸ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù…ÙÙ‚ÙˆØ¯Ø©."
        genai.configure(api_key=random.choice(keys))
        
        u = st.session_state.user_data
        lang_prompt = "Ø§Ø´Ø±Ø­ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©." if "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" in u['lang'] else "Explain in English."
        
        sys_prompt = f"""
        Ø£Ù†Øª Ø§Ù„Ø£Ø³ØªØ§Ø° Ø§Ù„Ø³ÙŠØ¯ Ø§Ù„Ø¨Ø¯ÙˆÙŠ. Ø§Ù„Ø·Ø§Ù„Ø¨: {u['name']} ({u['stage']}-{u['grade']}).
        Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª:
        1. Ø§Ù„ØªØ²Ù… Ø¨Ø§Ù„Ù…Ù†Ù‡Ø¬ Ø§Ù„Ù…ØµØ±ÙŠ.
        2. {lang_prompt}
        3. â›” ÙƒÙ† Ù…Ø®ØªØµØ±Ø§Ù‹ Ø¬Ø¯Ø§Ù‹ (Brief & Concise).
        4. âœ… Ø§Ø³ØªØ®Ø¯Ù… Ù†Ù‚Ø§Ø· (Bullet points).
        5. ÙƒÙ† Ù…Ø±Ø­Ø§Ù‹.
        """
        
        model_name = get_best_model()
        model = genai.GenerativeModel(model_name)
        
        inputs = [sys_prompt, user_text]
        if img_obj: inputs.extend([img_obj, "Ø§Ø´Ø±Ø­ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø®ØªØµØ§Ø±."])
        
        return model.generate_content(inputs).text
    except Exception as e: return f"Ø®Ø·Ø£: {e}"

# ==========================================
# 6. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø§Øª ÙˆØ§Ù„ØªØ´ØºÙŠÙ„
# ==========================================
def login_page():
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.markdown("### ğŸ” ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„")
        with st.form("login"):
            name = st.text_input("Ø§Ù„Ø§Ø³Ù…")
            code = st.text_input("Ø§Ù„ÙƒÙˆØ¯", type="password")
            st.markdown("---")
            c1, c2 = st.columns(2)
            with c1:
                stage = st.selectbox("Ø§Ù„Ù…Ø±Ø­Ù„Ø©", ["Ø§Ù„Ø§Ø¨ØªØ¯Ø§Ø¦ÙŠØ©", "Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ÙŠØ©", "Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©"])
                lang = st.selectbox("Ø§Ù„Ù„ØºØ©", ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"])
            with c2:
                grade = st.selectbox("Ø§Ù„ØµÙ", ["Ø§Ù„Ø±Ø§Ø¨Ø¹", "Ø§Ù„Ø®Ø§Ù…Ø³", "Ø§Ù„Ø³Ø§Ø¯Ø³", "Ø§Ù„Ø£ÙˆÙ„", "Ø§Ù„Ø«Ø§Ù†ÙŠ", "Ø§Ù„Ø«Ø§Ù„Ø«"])
            
            if st.form_submit_button("Ø¯Ø®ÙˆÙ„"):
                if code == TEACHER_KEY:
                    st.session_state.user_data.update({"logged_in": True, "role": "Teacher", "name": name})
                    st.rerun()
                elif check_student_code(code):
                    st.session_state.user_data.update({"logged_in": True, "role": "Student", "name": name, "stage": stage, "grade": grade, "lang": lang})
                    st.rerun()
                else:
                    st.error("Ø§Ù„ÙƒÙˆØ¯ Ø®Ø·Ø£")

def main_app():
    with st.sidebar:
        st.success(f"Ø£Ù‡Ù„Ø§Ù‹: {st.session_state.user_data['name']}")
        if st.button("Ø®Ø±ÙˆØ¬"):
            st.session_state.user_data["logged_in"] = False
            st.rerun()

    st.subheader("ğŸ’¬ Ø§Ø³Ø£Ù„ Ø§Ù„Ù…Ø¹Ù„Ù… (ØªØ­Ø¯Ø« Ø£Ùˆ Ø§ÙƒØªØ¨)")
    
    # Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†
    c_mic, c_img = st.columns([1, 1])
    with c_mic:
        st.info("ğŸ™ï¸ Ø§Ø¶ØºØ· Ù„Ù„ØªØ­Ø¯Ø«ØŒ ÙˆØ§Ø¶ØºØ· Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù„Ù„Ø¥Ø±Ø³Ø§Ù„:")
        # Ù‡Ø°Ø§ Ø§Ù„Ø²Ø± ÙŠØ¹ÙŠØ¯ Ø¨Ø§ÙŠØªØ§Øª Ø§Ù„ØµÙˆØª
        audio = mic_recorder(start_prompt="ØªØ³Ø¬ÙŠÙ„ âºï¸", stop_prompt="Ø¥Ø±Ø³Ø§Ù„ â¹ï¸", key='recorder')
    
    with c_img:
        with st.expander("ğŸ“¸ Ø¥Ø±ÙØ§Ù‚ ØµÙˆØ±Ø©"):
            f = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø©", type=['jpg', 'png'])
            img = Image.open(f) if f else None
            if img: st.image(img, width=150)

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„ØµÙˆØªÙŠ
    voice_text = None
    if audio:
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø³Ù…Ø§Ø¹Ùƒ..."):
            voice_text = speech_to_text(audio['bytes'])
            if not voice_text:
                st.warning("âš ï¸ Ù„Ù… Ø£Ø³Ù…Ø¹ Ø¬ÙŠØ¯Ø§Ù‹ØŒ Ø­Ø§ÙˆÙ„ Ø§Ù„Ø§Ù‚ØªØ±Ø§Ø¨ Ù…Ù† Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†.")

    # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    # Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†ØµÙŠ
    text_input = st.chat_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ...")
    
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ (ØµÙˆØª Ø£Ùˆ Ù†Øµ)
    final_q = text_input if text_input else voice_text

    if final_q:
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø³Ø¤Ø§Ù„
        st.session_state.messages.append({"role": "user", "content": final_q})
        with st.chat_message("user"): st.write(final_q)
        
        # Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
        with st.chat_message("assistant"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ± ÙˆØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø±Ø¯ Ø§Ù„ØµÙˆØªÙŠ..."):
                # 1. Ø§Ù„Ù†Øµ
                resp_text = get_ai_response(final_q, img)
                st.write(resp_text)
                
                # 2. Ø§Ù„ØµÙˆØª (Edge TTS)
                audio_file = text_to_speech_pro(resp_text)
                if audio_file:
                    st.audio(audio_file, format='audio/mp3')
        
        st.session_state.messages.append({"role": "assistant", "content": resp_text})

if __name__ == "__main__":
    if st.session_state.user_data["logged_in"]:
        main_app()
    else:
        login_page()
