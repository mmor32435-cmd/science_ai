import streamlit as st
import time
import google.generativeai as genai
import asyncio
import edge_tts
import speech_recognition as sr
from streamlit_mic_recorder import mic_recorder
from io import BytesIO
import re
from datetime import datetime
import pytz
from PIL import Image
import PyPDF2

# ==========================================
# ğŸ›ï¸ Ù„ÙˆØ­Ø© ØªØ­ÙƒÙ… Ø§Ù„Ù…Ø¹Ù„Ù…
# ==========================================

# ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø§Ù„Ù…ÙˆØ­Ø¯Ø© Ù„Ù„Ø¯Ø®ÙˆÙ„
DAILY_PASSWORD = "SCIENCE_CHAT" 

# ØªÙˆÙ‚ÙŠØªÙƒ Ø§Ù„Ù…Ø­Ù„ÙŠ
MY_TIMEZONE = 'Africa/Cairo' 

# Ø§Ù„Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø© (Ø§Ù„Ø³Ø§Ø¹Ø© Ø¨Ù†Ø¸Ø§Ù… 24)
# 17 = 5 Ù…Ø³Ø§Ø¡Ù‹ | 19 = 7 Ù…Ø³Ø§Ø¡Ù‹ | 21 = 9 Ù…Ø³Ø§Ø¡Ù‹
ALLOWED_HOURS = [17, 19, 21] 

# ==========================================

st.set_page_config(page_title="Ù…Ù†ØµØ© Ø§Ù„Ù…Ù†Ø§Ù‚Ø´Ø© Ø§Ù„Ø°ÙƒÙŠØ©", page_icon="ğŸ’¡", layout="wide")

# --- 1. Ø¯Ø§Ù„Ø© Ø­Ø§Ø±Ø³ Ø§Ù„ÙˆÙ‚Øª (Time Guard) ---
def check_discussion_time():
    tz = pytz.timezone(MY_TIMEZONE)
    now = datetime.now(tz)
    current_hour = now.hour
    
    # Ù‡Ù„ Ø§Ù„Ø³Ø§Ø¹Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¶Ù…Ù† Ø§Ù„Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø©ØŸ
    if current_hour in ALLOWED_HOURS:
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ Ù„Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø³Ø§Ø¹Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
        minutes_passed = now.minute
        minutes_remaining = 60 - minutes_passed
        return True, f"âœ… Ø§Ù„Ø¬Ù„Ø³Ø© Ù…ÙØªÙˆØ­Ø©! Ù…ØªØ¨Ù‚ÙŠ {minutes_remaining} Ø¯Ù‚ÙŠÙ‚Ø© Ù„Ù„Ø¥ØºÙ„Ø§Ù‚."
    else:
        # Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£ ØªÙˆØ¶Ø­ Ø§Ù„Ù…ÙˆØ§Ø¹ÙŠØ¯
        msg = f"""
        ğŸ›‘ Ø§Ù„Ù…Ù†ØµØ© Ù…ØºÙ„Ù‚Ø© Ø­Ø§Ù„ÙŠØ§Ù‹.
        
        â° Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ù…Ù†Ø§Ù‚Ø´Ø© Ø§Ù„ÙŠÙˆÙ…ÙŠØ© (Ø¨ØªÙˆÙ‚ÙŠØª Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©):
        1ï¸âƒ£ Ù…Ù† 5:00 Ù… Ø¥Ù„Ù‰ 6:00 Ù…
        2ï¸âƒ£ Ù…Ù† 7:00 Ù… Ø¥Ù„Ù‰ 8:00 Ù…
        3ï¸âƒ£ Ù…Ù† 9:00 Ù… Ø¥Ù„Ù‰ 10:00 Ù…
        
        Ø§Ù„Ø³Ø§Ø¹Ø© Ø§Ù„Ø¢Ù†: {now.strftime('%I:%M %p')}
        """
        return False, msg

# ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙˆÙ‚Øª ÙÙˆØ±Ø§Ù‹
is_open, status_msg = check_discussion_time()

if not is_open:
    st.error(status_msg)
    st.image("https://cdn-icons-png.flaticon.com/512/2972/2972531.png", width=150)
    st.stop() # ÙŠØºÙ„Ù‚ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚

# --- 2. Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© (ØµÙˆØªØŒ PDFØŒ ØµÙˆØ±) ---

def prepare_text(text):
    text = re.sub(r'[\*\#\-\_]', '', text)
    return text

async def generate_speech(text, output_file, voice_code):
    clean_text = prepare_text(text)
    communicate = edge_tts.Communicate(clean_text, voice_code, rate="-5%")
    await communicate.save(output_file)

def speech_to_text(audio_bytes):
    r = sr.Recognizer()
    try:
        audio_file = sr.AudioFile(BytesIO(audio_bytes))
        with audio_file as source:
            r.adjust_for_ambient_noise(source)
            audio_data = r.record(source)
            text = r.recognize_google(audio_data, language="ar-EG")
            return text
    except:
        return None

def extract_text_from_pdf(pdf_file):
    reader = PyPDF2.PdfReader(pdf_file)
    text = ""
    for page in reader.pages:
        text += page.extract_text() + "\n"
    return text

# --- 3. Ø§ØªØµØ§Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ---
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    # Ù†Ø­ØªØ§Ø¬ Ù…ÙˆØ¯ÙŠÙ„ ÙŠØ¯Ø¹Ù… Ø§Ù„ØµÙˆØ± (Vision) Ù…Ø«Ù„ flash Ø£Ùˆ pro
    all_models = genai.list_models()
    vision_models = [m.name for m in all_models if 'generateContent' in m.supported_generation_methods and 'flash' in m.name]
    
    if vision_models:
        active_model = vision_models[0]
    else:
        # Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù„Ùˆ Ù„Ù… ÙŠØ¬Ø¯ flash
        active_model = "models/gemini-1.5-pro"
        
    model = genai.GenerativeModel(active_model)
except Exception as e:
    st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
    st.stop()

# ==========================================
# ===== 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ =====
# ==========================================

# ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„
if "logged_in" not in st.session_state:
    st.session_state.logged_in = False

if not st.session_state.logged_in:
    st.title("ğŸ” Ø¨ÙˆØ§Ø¨Ø© Ø§Ù„Ù…Ù†Ø§Ù‚Ø´Ø© Ø§Ù„Ø¹Ù„Ù…ÙŠØ©")
    st.success(status_msg) # Ù†Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© Ø£Ù† Ø§Ù„ÙˆÙ‚Øª Ù…ØªØ§Ø­
    pwd = st.text_input("ÙƒÙ„Ù…Ø© Ù…Ø±ÙˆØ± Ø§Ù„Ø¬Ù„Ø³Ø©:", type="password")
    if st.button("Ø¯Ø®ÙˆÙ„"):
        if pwd == DAILY_PASSWORD:
            st.session_state.logged_in = True
            st.rerun()
        else:
            st.error("ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± ØºÙŠØ± ØµØ­ÙŠØ­Ø©")
    st.stop()

# Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø¨Ø¹Ø¯ Ø§Ù„Ø¯Ø®ÙˆÙ„
st.sidebar.title("Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¬Ù„Ø³Ø©")
st.sidebar.info(status_msg)
st.sidebar.markdown("---")
st.sidebar.write("ğŸ”Š ØµÙˆØª Ø§Ù„Ù…Ø¹Ù„Ù…:")
voice_choice = st.sidebar.radio("Ø§Ø®ØªØ±:", ["Ù…Ø³ØªØ± Ø´Ø§ÙƒØ± (Ù…ØµØ±ÙŠ)", "Ù…Ø³ Ø³Ù„Ù…Ù‰ (Ù…ØµØ±ÙŠØ©)"])
voice_code = "ar-EG-ShakirNeural" if "Ø´Ø§ÙƒØ±" in voice_choice else "ar-EG-SalmaNeural"

st.title("ğŸ’¡ Ø³Ø§Ø­Ø© Ø§Ù„Ø­ÙˆØ§Ø± ÙˆØ§Ù„Ù…Ù†Ø§Ù‚Ø´Ø©")
st.caption("Ø§Ø³Ø£Ù„ØŒ Ù†Ø§Ù‚Ø´ØŒ Ø£Ø±Ø³Ù„ ØµÙˆØ±Ø§Ù‹ Ø£Ùˆ Ù…Ù„ÙØ§Øª.. Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ Ù…Ø¹Ùƒ!")

# --- Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª (Tabs) Ù„ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª ---
tab1, tab2, tab3 = st.tabs(["ğŸ™ï¸ ØªØ­Ø¯Ø« (ØµÙˆØª)", "âœï¸ ÙƒØªØ§Ø¨Ø© ÙˆØ³Ø¤Ø§Ù„", "ğŸ“ Ø±ÙØ¹ Ù…Ù„ÙØ§Øª/ØµÙˆØ±"])

user_input_content = None # Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
input_type = "text" # text, image, pdf

# --- ØªØ¨ÙˆÙŠØ¨ 1: Ø§Ù„ØµÙˆØª ---
with tab1:
    st.write("Ø§Ø¶ØºØ· ÙˆØªØ­Ø¯Ø« Ù„Ù„Ù†Ù‚Ø§Ø´:")
    audio_input = mic_recorder(start_prompt="ğŸ¤ ØªØ­Ø¯Ø«", stop_prompt="â¹ï¸ Ø¥Ø±Ø³Ø§Ù„", key='rec', format="wav")
    if audio_input:
        with st.spinner("ğŸ‘‚ Ø£Ø³Ù…Ø¹Ùƒ..."):
            text = speech_to_text(audio_input['bytes'])
            if text:
                user_input_content = text
                st.success(f"ğŸ—£ï¸ Ù‚Ù„Øª: {text}")

# --- ØªØ¨ÙˆÙŠØ¨ 2: Ø§Ù„ÙƒØªØ§Ø¨Ø© ---
with tab2:
    text_input = st.text_area("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø£Ùˆ Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ù…Ù†Ø§Ù‚Ø´Ø© Ù‡Ù†Ø§:", height=100)
    if st.button("Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù†Øµ") and text_input:
        user_input_content = text_input

# --- ØªØ¨ÙˆÙŠØ¨ 3: Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„ØµÙˆØ± ---
with tab3:
    uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© (Ù„Ù„Ù…Ø³Ø§Ø¦Ù„) Ø£Ùˆ Ù…Ù„Ù PDF (Ù„Ù„Ù…Ø°ÙƒØ±Ø§Øª)", type=['png', 'jpg', 'jpeg', 'pdf'])
    file_caption = st.text_input("Ø£Ø¶Ù Ø³Ø¤Ø§Ù„Ø§Ù‹ Ø­ÙˆÙ„ Ø§Ù„Ù…Ù„Ù (Ø§Ø®ØªÙŠØ§Ø±ÙŠ):")
    
    if st.button("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ù ÙˆÙ…Ù†Ø§Ù‚Ø´ØªÙ‡") and uploaded_file:
        if uploaded_file.type == "application/pdf":
            # Ù…Ø¹Ø§Ù„Ø¬Ø© PDF
            with st.spinner("ğŸ“„ Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù PDF..."):
                pdf_text = extract_text_from_pdf(uploaded_file)
                # Ù†Ø¯Ù…Ø¬ Ù†Øµ Ø§Ù„Ù€ PDF Ù…Ø¹ Ø³Ø¤Ø§Ù„ Ø§Ù„Ø·Ø§Ù„Ø¨
                user_input_content = f"Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù† Ø§Ù„Ù…Ù„Ù:\n{pdf_text}\n\nØ³Ø¤Ø§Ù„ÙŠ Ù‡Ùˆ: {file_caption}"
                input_type = "text" # Ù„Ø£Ù†Ù†Ø§ Ø­ÙˆÙ„Ù†Ø§ Ø§Ù„Ù€ PDF Ù„Ù†Øµ
        else:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±
            image = Image.open(uploaded_file)
            st.image(image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙÙ‚Ø©", width=300)
            user_input_content = [file_caption if file_caption else "Ø§Ø´Ø±Ø­ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø© Ø¹Ù„Ù…ÙŠØ§Ù‹", image]
            input_type = "image"

# ==========================================
# ===== 5. Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ§Ù„Ø±Ø¯ =====
# ==========================================

if user_input_content:
    with st.spinner("ğŸ§  Ø§Ù„Ù…Ø¹Ù„Ù… ÙŠÙÙƒØ± ÙˆÙŠØ­Ù„Ù„..."):
        try:
            # ØªØ¬Ù‡ÙŠØ² Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ (Prompt) Ù„Ù„Ù…Ù†Ø§Ù‚Ø´Ø©
            role_desc = "Ù…Ø¹Ù„Ù…Ø©" if "Ø³Ù„Ù…Ù‰" in voice_choice else "Ù…Ø¹Ù„Ù…"
            system_prompt = f"""
            Ø£Ù†Øª {role_desc} Ø¹Ù„ÙˆÙ… Ù…ØµØ±ÙŠ Ù…Ø­Ø¨ Ù„Ù„Ù†Ù‚Ø§Ø´ ÙˆØ§Ù„Ø­ÙˆØ§Ø±.
            - Ù‡Ø¯ÙÙƒ Ù„ÙŠØ³ Ù…Ø¬Ø±Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©ØŒ Ø¨Ù„ ÙØªØ­ Ø­ÙˆØ§Ø± ÙˆÙÙ‡Ù… Ø¹Ù…Ù‚ Ø³Ø¤Ø§Ù„ Ø§Ù„Ø·Ø§Ù„Ø¨.
            - ØªØ­Ø¯Ø« Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ© Ø§Ù„Ø±Ø§Ù‚ÙŠØ© (Ø¨Ø³Ø§Ø·Ø© Ù…Ø¹ Ø¯Ù‚Ø© Ø¹Ù„Ù…ÙŠØ©).
            - Ø¥Ø°Ø§ Ø£Ø±Ø³Ù„ Ø§Ù„Ø·Ø§Ù„Ø¨ ØµÙˆØ±Ø©ØŒ Ø§Ø´Ø±Ø­ ØªÙØ§ØµÙŠÙ„Ù‡Ø§ Ø¨Ø¯Ù‚Ø©.
            - Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ ÙŠØ­ØªØ§Ø¬ ØªÙÙƒÙŠØ±Ø§Ù‹ØŒ Ø§Ø´Ø±Ø­ Ø§Ù„Ø®Ø·ÙˆØ§Øª "ÙˆØ§Ø­Ø¯Ø© ÙˆØ§Ø­Ø¯Ø©".
            - Ø§Ø³ØªØ®Ø¯Ù… Ø¹Ø¨Ø§Ø±Ø§Øª Ø­ÙˆØ§Ø±ÙŠØ© Ù…Ø«Ù„: (Ø¨Øµ ÙŠØ§ Ø³ÙŠØ¯ÙŠØŒ Ø®Ø¯ Ø¨Ø§Ù„Ùƒ Ù…Ù† Ø§Ù„Ù†Ù‚Ø·Ø© Ø¯ÙŠØŒ Ø¥ÙŠÙ‡ Ø±Ø£ÙŠÙƒ Ù„Ùˆ...).
            - Ø§Ø¬Ø¹Ù„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø³Ù…ÙˆØ¹Ø© (ØªØ¬Ù†Ø¨ Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©).
            """
            
            # Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
            if input_type == "image":
                # Ù„Ù„ØµÙˆØ±Ø© Ù†Ø±Ø³Ù„ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© [Ø§Ù„Ù†Øµ, Ø§Ù„ØµÙˆØ±Ø©]
                full_prompt = [system_prompt, user_input_content[0], user_input_content[1]]
                response = model.generate_content(full_prompt)
            else:
                # Ù„Ù„Ù†Øµ Ù†Ø±Ø³Ù„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¯Ù…Ø¬
                full_prompt = f"{system_prompt}\n\nØ³Ø¤Ø§Ù„ Ø§Ù„Ø·Ø§Ù„Ø¨/Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„Ù:\n{user_input_content}"
                response = model.generate_content(full_prompt)
            
            # Ø§Ù„Ø¹Ø±Ø¶
            st.markdown("---")
            st.markdown(f"### ğŸ“˜ Ø±Ø¯ {role_desc}:")
            st.write(response.text)
            
            # Ø§Ù„ØµÙˆØª
            output_file = "response.mp3"
            asyncio.run(generate_speech(response.text, output_file, voice_code))
            st.audio(output_file, format='audio/mp3', autoplay=True)
            
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {e}")
            if "404" in str(e):
                st.warning("Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ… ÙÙŠ Ù…Ù†Ø·Ù‚ØªÙƒ Ù„Ù„ØµÙˆØ±ØŒ Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Øµ ÙÙ‚Ø·.")

st.markdown("---")
