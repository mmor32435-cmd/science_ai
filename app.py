import streamlit as st
import time
import google.generativeai as genai
import asyncio
import edge_tts
import speech_recognition as sr
from streamlit_mic_recorder import mic_recorder
from io import BytesIO

# ===== 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© =====
st.set_page_config(page_title="Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„ØµÙˆØªÙŠ", page_icon="ğŸ™ï¸", layout="centered")

# --- Ø¯Ø§Ù„Ø© Ù†Ø·Ù‚ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ---
async def generate_speech(text, output_file):
    communicate = edge_tts.Communicate(text, "ar-EG-ShakirNeural")
    await communicate.save(output_file)

# --- Ø¯Ø§Ù„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ù„Ù†Øµ ---
def speech_to_text(audio_bytes):
    r = sr.Recognizer()
    try:
        audio_file = sr.AudioFile(BytesIO(audio_bytes))
        with audio_file as source:
            r.adjust_for_ambient_noise(source)
            audio_data = r.record(source)
            # Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… (Ø¹Ø±Ø¨ÙŠ)
            text = r.recognize_google(audio_data, language="ar-EG")
            return text
    except:
        return None

# --- Ø§Ù„Ø§ØªØµØ§Ù„ Ø§Ù„Ø°ÙƒÙŠ ÙˆØ§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ---
active_model_name = "ØºÙŠØ± Ù…ØªØµÙ„"
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
    
    # 1. Ù†Ø·Ù„Ø¨ Ù…Ù† Ø¬ÙˆØ¬Ù„ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª
    all_models = genai.list_models()
    
    # 2. Ù†ÙÙ„ØªØ± Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ù„Ù†Ø£Ø®Ø° ÙÙ‚Ø· Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„ØªÙŠ ØªÙˆÙ„Ø¯ Ù†ØµÙˆØµØ§Ù‹
    my_models = []
    for m in all_models:
        if 'generateContent' in m.supported_generation_methods:
            my_models.append(m.name)
    
    if len(my_models) == 0:
        st.error("âŒ Ø­Ø³Ø§Ø¨Ùƒ Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£ÙŠ Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ù…ØªØ§Ø­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹.")
        st.stop()
        
    # 3. Ù†Ø®ØªØ§Ø± Ø£Ø­Ø¯Ø« Ù…ÙˆØ¯ÙŠÙ„ Ù…ØªØ§Ø­ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
    # Ù†Ø­Ø§ÙˆÙ„ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…ÙˆØ¯ÙŠÙ„Ø§Øª flash Ø£Ùˆ pro Ø£ÙˆÙ„Ø§Ù‹
    preferred_model = None
    for m in my_models:
        if 'flash' in m:
            preferred_model = m
            break
    if not preferred_model:
        for m in my_models:
            if 'pro' in m:
                preferred_model = m
                break
    
    # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø§Ù„Ù…ÙØ¶Ù„ÙŠÙ†ØŒ Ù†Ø£Ø®Ø° Ø£ÙˆÙ„ ÙˆØ§Ø­Ø¯ ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ÙˆØ®Ù„Ø§Øµ
    if not preferred_model:
        preferred_model = my_models[0]
        
    active_model_name = preferred_model
    model = genai.GenerativeModel(active_model_name)
    
except Exception as e:
    st.error(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
    st.stop()

# ===== 2. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© =====
st.title("ğŸ™ï¸ Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ (Ù…Ø­Ø§Ø¯Ø«Ø©)")
# Ù†Ø¹Ø±Ø¶ Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø°ÙŠ ØªÙ… Ø§Ø®ØªÙŠØ§Ø±Ù‡ Ø¨Ù†Ø¬Ø§Ø­
st.caption(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØªØ´ØºÙŠÙ„Ù‡: `{active_model_name}`")

# ===== 3. Ø§Ù„Ø¯Ø®ÙˆÙ„ =====
if "logged_in" not in st.session_state:
    password = st.text_input("ğŸ”‘ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±", type="password")
    if password == "SCIENCE60":
        st.session_state.logged_in = True
        st.rerun()
    elif password: st.warning("Ø®Ø·Ø£")
    st.stop()

# ===== 4. Ø§Ù„Ø¹Ø¯Ø§Ø¯ =====
if "start_time" not in st.session_state: st.session_state.start_time = time.time()
remaining = 3600 - (time.time() - st.session_state.start_time)
if remaining <= 0: st.error("Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ÙˆÙ‚Øª"); st.stop()
st.info(f"â³ Ø§Ù„ÙˆÙ‚Øª: {int(remaining//60)} Ø¯Ù‚ÙŠÙ‚Ø©")

# ===== 5. Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© =====
st.markdown("---")
st.subheader("ØªØ­Ø¯Ø« Ø§Ù„Ø¢Ù† ğŸ‘‡")

audio_input = mic_recorder(
    start_prompt="ğŸ¤ Ø§Ø¶ØºØ· Ù„Ù„ØªØ­Ø¯Ø«",
    stop_prompt="â¹ï¸ Ø§Ø¶ØºØ· Ù„Ù„Ø¥Ù†Ù‡Ø§Ø¡",
    key='recorder',
    format="wav"
)

if audio_input:
    with st.spinner("ğŸ‘‚ Ø£Ø³Ù…Ø¹Ùƒ..."):
        user_text = speech_to_text(audio_input['bytes'])
    
    if user_text:
        st.success(f"ğŸ—£ï¸: {user_text}")
        with st.spinner("ğŸ§  Ø£ÙÙƒØ±..."):
            try:
                # ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ù…Ø¯Ø±Ø³
                prompt = f"Ø£Ù†Øª Ù…Ø¹Ù„Ù… Ø¹Ù„ÙˆÙ… Ù…Ø±Ø­. Ø£Ø¬Ø¨ Ø¨Ø§Ø®ØªØµØ§Ø± ÙˆØ¨Ø§Ù„Ø¹Ø§Ù…ÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ© Ø§Ù„Ø¨Ø³ÙŠØ·Ø© Ø¹Ù„Ù‰: {user_text}"
                response = model.generate_content(prompt)
                
                st.markdown(f"### ğŸ“˜: {response.text}")
                
                asyncio.run(generate_speech(response.text, "audio.mp3"))
                st.audio("audio.mp3", format='audio/mp3', autoplay=True)
            except Exception as e:
                st.error(f"Ø®Ø·Ø£: {e}")
    else:
        st.warning("âš ï¸ Ø§Ù„ØµÙˆØª ØºÙŠØ± ÙˆØ§Ø¶Ø­")

st.markdown("---")
