import streamlit as st
import time
import google.generativeai as genai
import asyncio
import edge_tts
import speech_recognition as sr
from streamlit_mic_recorder import mic_recorder
from io import BytesIO
import re

# ===== 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© =====
st.set_page_config(page_title="Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ", page_icon="ğŸ™ï¸", layout="centered")

# --- Ø¯Ø§Ù„Ø© ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ ---
def prepare_text(text):
    text = re.sub(r'[\*\#\-\_]', '', text)
    return text

# --- Ø¯Ø§Ù„Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª (Ø£ØµÙˆØ§Øª Ø®Ù„ÙŠØ¬ÙŠØ© ÙØ®Ù…Ø©) ---
async def generate_speech(text, output_file, voice_code):
    clean_text = prepare_text(text)
    # Ø§Ù„Ø³Ø±Ø¹Ø© Ø·Ø¨ÙŠØ¹ÙŠØ© (0%) Ù„Ø¶Ù…Ø§Ù† Ù…Ø®Ø§Ø±Ø¬ Ø§Ù„Ø­Ø±ÙˆÙ
    communicate = edge_tts.Communicate(clean_text, voice_code, rate="+0%")
    await communicate.save(output_file)

# --- Ø¯Ø§Ù„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ù„Ù†Øµ ---
def speech_to_text(audio_bytes):
    r = sr.Recognizer()
    try:
        audio_file = sr.AudioFile(BytesIO(audio_bytes))
        with audio_file as source:
            r.adjust_for_ambient_noise(source)
            audio_data = r.record(source)
            # Ù†Ø­Ø§ÙˆÙ„ Ø§Ù„ØªØ¹Ø±Ù Ø¨Ù„Ù‡Ø¬Ø© Ø¹Ø§Ù…Ø©
            text = r.recognize_google(audio_data, language="ar-SA")
            return text
    except:
        return None

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ø¬ÙˆØ¬Ù„ ---
try:
    if "GOOGLE_API_KEY" in st.secrets:
        genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    else:
        st.error("Ù…ÙØªØ§Ø­ Ø¬ÙˆØ¬Ù„ Ù…ÙÙ‚ÙˆØ¯!"); st.stop()
        
    all_models = genai.list_models()
    my_models = [m.name for m in all_models if 'generateContent' in m.supported_generation_methods]
    active_model = next((m for m in my_models if 'flash' in m), my_models[0])
    model = genai.GenerativeModel(active_model)
except:
    st.error("Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø¬ÙˆØ¬Ù„"); st.stop()

# ===== 2. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© =====
st.title("ğŸ™ï¸ Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ")
st.caption("ÙŠØ¹Ù…Ù„ Ø¨Ø£ØµÙˆØ§Øª Ø¹Ø±Ø¨ÙŠØ© ÙØµÙŠØ­Ø© Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø© (Ù…Ø¬Ø§Ù†ÙŠ)")

# --- Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØµÙˆØª (Ø£ØµÙˆØ§Øª Ø¬Ø¯ÙŠØ¯Ø©) ---
st.subheader("ğŸ”Š Ø§Ø®ØªØ± Ø§Ù„Ù…Ø¹Ù„Ù‚ Ø§Ù„ØµÙˆØªÙŠ")
voice_options = {
    "ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø£Ø³ØªØ§Ø° Ø­Ø§Ù…Ø¯ (ØµÙˆØª ÙØ®ÙŠÙ… ÙˆØ±Ø²ÙŠÙ†)": "ar-SA-HamedNeural",
    "ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø£Ø³ØªØ§Ø°Ø© Ø²Ø§Ø±ÙŠØ© (ØµÙˆØª Ø¥Ø®Ø¨Ø§Ø±ÙŠ ÙˆØ§Ø¶Ø­)": "ar-SA-ZariyahNeural",
    "ğŸ‡¯ğŸ‡´ Ø§Ù„Ø£Ø³ØªØ§Ø° ØªÙŠÙ… (ØµÙˆØª Ø¹Ø±Ø¨ÙŠ Ù…Ø­Ø§ÙŠØ¯)": "ar-JO-TaimNeural"
}
selected_voice_name = st.selectbox("Ø§Ù„Ù…ØªØ­Ø¯Ø«:", list(voice_options.keys()))
selected_voice_code = voice_options[selected_voice_name]

# ===== 3. Ø§Ù„Ø¯Ø®ÙˆÙ„ =====
if "logged_in" not in st.session_state:
    password = st.text_input("ğŸ”‘ Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ø³Ø±ÙŠ", type="password")
    if password == "SCIENCE60":
        st.session_state.logged_in = True
        st.rerun()
    elif password: st.warning("Ø®Ø·Ø£")
    st.stop()

# ===== 4. Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© =====
st.markdown("---")
st.write("Ø§Ø¶ØºØ· ÙˆØªØ­Ø¯Ø«:")

audio_input = mic_recorder(
    start_prompt="ğŸ¤ ØªØ­Ø¯Ø« Ø§Ù„Ø¢Ù†",
    stop_prompt="â¹ï¸ Ø¥Ø±Ø³Ø§Ù„",
    key='recorder',
    format="wav"
)

if audio_input:
    with st.spinner("ğŸ‘‚ Ø£Ø³Ù…Ø¹Ùƒ..."):
        user_text = speech_to_text(audio_input['bytes'])
    
    if user_text:
        st.success(f"ğŸ—£ï¸: {user_text}")
        with st.spinner("ğŸ§  Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ø¶ÙŠØ±..."):
            try:
                # ØªÙˆØ¬ÙŠÙ‡ Ù„Ù„ØªØ­Ø¯Ø« Ø¨Ø§Ù„ÙØµØ­Ù‰ Ø§Ù„Ø¨Ø³ÙŠØ·Ø© Ù„Ø£Ù†Ù‡Ø§ Ø§Ù„Ø£Ù†Ø³Ø¨ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø£ØµÙˆØ§Øª
                prompt = f"""
                Ø£Ù†Øª Ù…Ø¹Ù„Ù… Ø¹Ù„ÙˆÙ… Ù…ØªÙ…ÙŠØ².
                Ø§Ù„Ø³Ø¤Ø§Ù„: '{user_text}'
                Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª:
                1. Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø§Ù„Ø¨Ø³ÙŠØ·Ø© ÙˆØ§Ù„ÙˆØ§Ø¶Ø­Ø© (ØªÙ„ÙŠÙ‚ Ø¨Ø§Ù„ØµÙˆØª Ø§Ù„Ø±Ø²ÙŠÙ†).
                2. Ø§Ø¬Ø¹Ù„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù‚ØµÙŠØ±Ø© ÙˆÙ…Ø¨Ø§Ø´Ø±Ø©.
                3. ØªØ¬Ù†Ø¨ Ø§Ù„Ø±Ù…ÙˆØ² ÙˆØ§Ù„Ù‚ÙˆØ§Ø¦Ù….
                """
                
                response = model.generate_content(prompt)
                st.markdown(f"### ğŸ“˜ Ø§Ù„Ø±Ø¯:\n{response.text}")
                
                output_file = "response.mp3"
                asyncio.run(generate_speech(response.text, output_file, selected_voice_code))
                st.audio(output_file, format='audio/mp3', autoplay=True)
                
            except Exception as e:
                st.error(f"Ø®Ø·Ø£: {e}")
    else:
        st.warning("âš ï¸ Ø§Ù„ØµÙˆØª ØºÙŠØ± ÙˆØ§Ø¶Ø­")
