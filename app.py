import streamlit as st
import google.generativeai as genai
import requests
import tempfile
import os
import json
import time
import asyncio
import random
from io import BytesIO

# Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„ØµÙˆØª (ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯Ù‡Ø§ ÙÙŠ requirements.txt)
from streamlit_mic_recorder import mic_recorder
import edge_tts
import speech_recognition as sr

# =========================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
# =========================
st.set_page_config(
    page_title="Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ | Ù…Ù†Ù‡Ø§Ø¬ Ù…ØµØ±",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
html, body, .stApp { font-family: 'Cairo', sans-serif !important; direction: rtl; text-align: right; }
.header-box { background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%); padding: 2rem; border-radius: 20px; text-align: center; color: white; margin-bottom: 20px; box-shadow: 0 4px 15px rgba(0,0,0,0.1); }
.stButton>button { background: #2a5298; color: white; border-radius: 10px; height: 50px; width: 100%; font-size: 18px; border: none; transition: 0.3s; }
.stButton>button:hover { background: #1e3c72; transform: scale(1.02); }
</style>
""", unsafe_allow_html=True)

# Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙØ§ØªÙŠØ­
GOOGLE_API_KEYS = st.secrets.get("GOOGLE_API_KEYS", [])
if isinstance(GOOGLE_API_KEYS, str):
    GOOGLE_API_KEYS = [k.strip() for k in GOOGLE_API_KEYS.split(",") if k.strip()]

# =========================
# 2. Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„)
# =========================
def configure_genai():
    if not GOOGLE_API_KEYS:
        st.error("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙØ§ØªÙŠØ­ API")
        return False
    
    # Ø§Ø®ØªÙŠØ§Ø± Ù…ÙØªØ§Ø­ Ø¹Ø´ÙˆØ§Ø¦ÙŠ ÙˆØªÙØ¹ÙŠÙ„Ù‡
    selected_key = random.choice(GOOGLE_API_KEYS)
    genai.configure(api_key=selected_key)
    return True

def get_best_available_model():
    """Ø¯Ø§Ù„Ø© Ø°ÙƒÙŠØ© ØªØ¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…ØªØ§Ø­ ÙˆØªØ®ØªØ§Ø±Ù‡ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹"""
    try:
        # Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ù„Ù„Ù…ÙØªØ§Ø­
        models = list(genai.list_models())
        
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª (Ù†ÙØ¶Ù„ 1.5 Ù„Ø£Ù†Ù‡ ÙŠØ³ØªÙˆØ¹Ø¨ ÙƒØªØ¨ ÙƒØ¨ÙŠØ±Ø©)
        priorities = [
            'gemini-1.5-flash',
            'gemini-1.5-pro',
            'gemini-1.5-flash-latest',
            'gemini-1.0-pro',
            'gemini-pro'
        ]
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„ Ù…ØªØ§Ø­ ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
        for priority in priorities:
            for m in models:
                if priority in m.name and 'generateContent' in m.supported_generation_methods:
                    return m.name
        
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø§Ù„Ù…ÙØ¶Ù„ØŒ Ù†Ø£Ø®Ø° Ø£ÙŠ Ù…ÙˆØ¯ÙŠÙ„ ÙŠØ¯Ø¹Ù… Ø§Ù„ØªÙˆÙ„ÙŠØ¯
        for m in models:
            if 'generateContent' in m.supported_generation_methods:
                return m.name
                
        return "gemini-pro" # Ø§Ù„Ø­Ù„ Ø§Ù„Ø£Ø®ÙŠØ±
    except Exception as e:
        st.warning(f"ØªØ¹Ø°Ø± Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§ØªØŒ Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ. Ø§Ù„Ø®Ø·Ø£: {e}")
        return "gemini-1.5-flash"

def upload_to_gemini(path, mime_type="application/pdf"):
    """Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ù„Ø³Ø­Ø§Ø¨Ø© Ø¬ÙˆØ¬Ù„"""
    try:
        file = genai.upload_file(path, mime_type=mime_type)
        # Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        while file.state.name == "PROCESSING":
            time.sleep(2)
            file = genai.get_file(file.name)
        return file
    except Exception as e:
        st.error(f"ÙØ´Ù„ Ø§Ù„Ø±ÙØ¹ Ù„Ø³Ø­Ø§Ø¨Ø© Ø¬ÙˆØ¬Ù„: {e}")
        return None

def get_model_session(file_attachment=None):
    """ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø´Ø§Øª Ø¨Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ø®ØªØ§Ø± ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹"""
    
    # 1. Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„
    model_name = get_best_available_model()
    # st.toast(f"ØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„: {model_name}") # (Ø§Ø®ØªÙŠØ§Ø±ÙŠ: Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„)

    config = {
        "temperature": 0.3,
        "top_p": 0.95,
        "top_k": 64,
        "max_output_tokens": 8192,
    }
    
    system_prompt = """Ø£Ù†Øª Ù…Ø¹Ù„Ù… Ø®Ø¨ÙŠØ± ÙÙŠ Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„Ù…ØµØ±ÙŠØ©.
    Ø¯ÙˆØ±Ùƒ Ù‡Ùˆ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø·Ø§Ù„Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„Ù…Ø¯Ø±Ø³ÙŠ Ø§Ù„Ù…Ø±ÙÙ‚ ÙÙ‚Ø·.
    - Ø§Ø´Ø±Ø­ Ø¨ÙˆØ¶ÙˆØ­ ÙˆØ¨Ø³Ø§Ø·Ø©.
    - Ø¹Ù†Ø¯ Ø·Ù„Ø¨ Ø§Ø®ØªØ¨Ø§Ø±ØŒ Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ù† Ø§Ù„ÙƒØªØ§Ø¨.
    - Ø¹Ù†Ø¯ Ø§Ù„ØªØµØ­ÙŠØ­ØŒ ÙƒÙ† Ø¯Ù‚ÙŠÙ‚Ø§Ù‹ ÙˆØ£Ø¹Ø· Ø¯Ø±Ø¬Ø© Ù…Ù† 10.
    """
    
    model = genai.GenerativeModel(
        model_name=model_name,
        generation_config=config,
        system_instruction=system_prompt
    )
    
    history = []
    if file_attachment:
        history.append({"role": "user", "parts": [file_attachment, "Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„Ù…Ø¯Ø±Ø³ÙŠ. Ø§Ø¹ØªÙ…Ø¯ Ø¹Ù„ÙŠÙ‡ ÙÙŠ Ø§Ù„Ø´Ø±Ø­."]})
        history.append({"role": "model", "parts": ["Ø­Ø³Ù†Ø§Ù‹ØŒ Ù„Ù‚Ø¯ Ø§Ø³ØªÙˆØ¹Ø¨Øª Ø§Ù„ÙƒØªØ§Ø¨ ÙƒØ§Ù…Ù„Ø§Ù‹ ÙˆØ£Ù†Ø§ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø´Ø±Ø­ ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø±."]})
    
    return model.start_chat(history=history)

# =========================
# 3. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„
# =========================
def load_book_from_url(url):
    try:
        response = requests.get(url, stream=True)
        if response.status_code == 200:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                for chunk in response.iter_content(chunk_size=8192):
                    tmp.write(chunk)
                return tmp.name
    except: pass
    return None

# =========================
# 4. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# =========================
def main():
    if "chat_session" not in st.session_state:
        st.session_state.chat_session = None
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # --- Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© ---
    with st.sidebar:
        st.header("ğŸ“š Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ÙƒØªØ§Ø¨")
        
        # Ø®ÙŠØ§Ø±Ø§Øª Ù…Ø¨Ø³Ø·Ø©
        upload_option = st.radio("Ø§Ù„Ù…ØµØ¯Ø±", ["Ø±ÙØ¹ Ù…Ù„Ù PDF", "Ø±Ø§Ø¨Ø· Ù…Ø¨Ø§Ø´Ø±"])
        
        if upload_option == "Ø±ÙØ¹ Ù…Ù„Ù PDF":
            uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ÙƒØªØ§Ø¨ Ø§Ù„ÙˆØ²Ø§Ø±Ø©", type=['pdf'])
            if uploaded_file and st.button("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ø¯Ø±Ø§Ø³Ø©"):
                with st.status("Ø¬Ø§Ø±ÙŠ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ÙƒØªØ§Ø¨ Ù„Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ..."):
                    # Ø­ÙØ¸ Ù…Ø¤Ù‚Øª
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                        tmp.write(uploaded_file.getvalue())
                        local_path = tmp.name
                    
                    if configure_genai():
                        gemini_file = upload_to_gemini(local_path)
                        if gemini_file:
                            st.session_state.chat_session = get_model_session(gemini_file)
                            st.session_state.messages = []
                            st.success("ØªÙ… Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ÙƒØªØ§Ø¨ Ø¨Ù†Ø¬Ø§Ø­!")
                            
        else:
            url = st.text_input("Ù„ØµÙ‚ Ø±Ø§Ø¨Ø· Ø§Ù„ÙƒØªØ§Ø¨")
            if url and st.button("ØªØ­Ù…ÙŠÙ„"):
                with st.status("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„ ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©..."):
                    local_path = load_book_from_url(url)
                    if local_path and configure_genai():
                        gemini_file = upload_to_gemini(local_path)
                        if gemini_file:
                            st.session_state.chat_session = get_model_session(gemini_file)
                            st.session_state.messages = []
                            st.success("ØªÙ…!")

        if st.session_state.chat_session:
            if st.button("Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ø¬Ù„Ø³Ø©"):
                st.session_state.chat_session = None
                st.session_state.messages = []
                st.rerun()

    # --- Ø§Ù„Ø´Ø§Ø´Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---
    st.markdown(f"""
    <div class="header-box">
        <h1>Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ | Ù…Ù†Ù‡Ø§Ø¬ Ù…ØµØ±</h1>
    </div>
    """, unsafe_allow_html=True)

    if not st.session_state.chat_session:
        st.info("ğŸ‘ˆ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ ÙƒØªØ§Ø¨ Ø§Ù„Ù…Ø¯Ø±Ø³Ø© Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© Ù„Ù„Ø¨Ø¯Ø¡.")
        return

    # Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª
    tabs = st.tabs(["ğŸ’¬ Ø§Ø³Ø£Ù„ ÙˆØ§ÙÙ‡Ù…", "ğŸ“ Ø§Ø®ØªØ¨Ø± Ù†ÙØ³Ùƒ", "âœ… ØµØ­Ø­ ÙˆØ§Ø¬Ø¨Ùƒ"])

    # 1. ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø´Ø§Øª
    with tabs[0]:
        for msg in st.session_state.messages:
            role = "user" if msg["role"] == "user" else "assistant"
            with st.chat_message(role):
                st.write(msg["content"])

        c1, c2 = st.columns([1, 8])
        with c1: audio = mic_recorder(start_prompt="ğŸ™ï¸", stop_prompt="ğŸ›‘", key="mic")
        with c2: prompt = st.chat_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§...")

        input_text = prompt
        if not input_text and audio:
            r = sr.Recognizer()
            try:
                with sr.AudioFile(BytesIO(audio['bytes'])) as source:
                    input_text = r.recognize_google(r.record(source), language="ar-EG")
            except: pass

        if input_text:
            st.session_state.messages.append({"role": "user", "content": input_text})
            with st.chat_message("user"): st.write(input_text)
            
            with st.chat_message("assistant"):
                with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ±..."):
                    try:
                        response = st.session_state.chat_session.send_message(input_text)
                        st.write(response.text)
                        st.session_state.messages.append({"role": "model", "content": response.text})
                        
                        if st.checkbox("Ù‚Ø±Ø§Ø¡Ø© ØµÙˆØªÙŠØ©", value=True, key="tts_chat"):
                            async def play():
                                v = edge_tts.Communicate(response.text, "ar-EG-ShakirNeural")
                                with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as f:
                                    await v.save(f.name)
                                    st.audio(f.name)
                            asyncio.run(play())
                    except Exception as e:
                        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")

    # 2. ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    with tabs[1]:
        col1, col2 = st.columns(2)
        topic = col1.text_input("Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± (Ù…Ø«Ù„Ø§Ù‹: Ø§Ù„Ø¯Ø±Ø³ Ø§Ù„Ø£ÙˆÙ„)")
        level = col2.selectbox("Ø§Ù„Ù…Ø³ØªÙˆÙ‰", ["Ø³Ù‡Ù„", "Ù…ØªÙˆØ³Ø·", "ØµØ¹Ø¨"])
        
        if st.button("Ø£Ù†Ø´Ø¦ Ù„ÙŠ Ø§Ø®ØªØ¨Ø§Ø±Ø§Ù‹"):
            if topic:
                p = f"Ø£Ù†Ø´Ø¦ Ø§Ø®ØªØ¨Ø§Ø± {level} Ø¹Ù† '{topic}' Ù…Ù† Ø§Ù„ÙƒØªØ§Ø¨. 5 Ø£Ø³Ø¦Ù„Ø© ÙÙ‚Ø·. Ù„Ø§ ØªØ¸Ù‡Ø± Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª."
                with st.spinner("Ø¬Ø§Ø±ÙŠ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø©..."):
                    try:
                        resp = st.session_state.chat_session.send_message(p)
                        st.markdown(resp.text)
                    except Exception as e: st.error(f"Ø®Ø·Ø£: {e}")

    # 3. ØªØ¨ÙˆÙŠØ¨ Ø§Ù„ØªØµØ­ÙŠØ­
    with tabs[2]:
        q_val = st.text_input("Ø§Ù„Ø³Ø¤Ø§Ù„:")
        a_val = st.text_area("Ø¥Ø¬Ø§Ø¨ØªÙƒ:")
        if st.button("ØµØ­Ø­ Ù„ÙŠ"):
            if q_val and a_val:
                p = f"Ø§Ù„Ø³Ø¤Ø§Ù„: {q_val}\nØ¥Ø¬Ø§Ø¨ØªÙŠ: {a_val}\nØµØ­Ø­ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù† Ø§Ù„ÙƒØªØ§Ø¨ ÙˆØ£Ø¹Ø·Ù†ÙŠ Ø¯Ø±Ø¬Ø© Ù…Ù† 10."
                with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØµØ­ÙŠØ­..."):
                    try:
                        resp = st.session_state.chat_session.send_message(p)
                        st.success(resp.text)
                    except Exception as e: st.error(f"Ø®Ø·Ø£: {e}")

if __name__ == "__main__":
    main()
