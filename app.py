import streamlit as st
from google.oauth2 import service_account
import google.generativeai as genai
import gspread
from PIL import Image
import random
import speech_recognition as sr
from gtts import gTTS
from streamlit_mic_recorder import mic_recorder
import io
import tempfile

# ==========================================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
# ==========================================
st.set_page_config(
    page_title="Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø¹Ù„Ù…ÙŠ | Ø§Ù„Ø³ÙŠØ¯ Ø§Ù„Ø¨Ø¯ÙˆÙŠ",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==========================================
# 2. Ø§Ù„ØªØµÙ…ÙŠÙ… (CSS)
# ==========================================
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
    html, body, [class*="css"] { font-family: 'Cairo', sans-serif; direction: rtl; text-align: right; }
    .stApp { background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%); }
    .header-box {
        background: linear-gradient(90deg, #141E30 0%, #243B55 100%);
        padding: 2rem; border-radius: 15px; color: white; text-align: center; margin-bottom: 2rem;
    }
    .stButton>button { background-color: #243B55; color: white; border-radius: 10px; height: 50px; width: 100%; font-weight: bold; }
    
    /* ØªÙ†Ø³ÙŠÙ‚ Ø²Ø± Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† */
    .mic-btn { text-align: center; margin: 10px 0; }
</style>
""", unsafe_allow_html=True)

st.markdown("""
<div class="header-box">
    <h1>Ø§Ù„Ø£Ø³ØªØ§Ø° / Ø§Ù„Ø³ÙŠØ¯ Ø§Ù„Ø¨Ø¯ÙˆÙŠ</h1>
    <h3>Mr. Elsayed Elbadawy - Expert Science Tutor</h3>
</div>
""", unsafe_allow_html=True)

# ==========================================
# 3. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¬Ù„Ø³Ø©
# ==========================================
if 'user_data' not in st.session_state:
    st.session_state.user_data = {
        "logged_in": False, "role": None, "name": "", "grade": "", "stage": "", "lang": ""
    }

if 'messages' not in st.session_state: st.session_state.messages = []

# ==========================================
# 4. Ø¯ÙˆØ§Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ (Backend)
# ==========================================
TEACHER_KEY = st.secrets.get("TEACHER_MASTER_KEY", "ADMIN")
SHEET_NAME = st.secrets.get("CONTROL_SHEET_NAME", "App_Control")

@st.cache_resource
def get_gspread_client():
    if "gcp_service_account" not in st.secrets: return None
    try:
        creds_dict = dict(st.secrets["gcp_service_account"])
        if "private_key" in creds_dict:
            creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
        
        scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
        creds = service_account.Credentials.from_service_account_info(creds_dict, scopes=scopes)
        return gspread.authorize(creds)
    except: return None

def check_student_code(input_code):
    client = get_gspread_client()
    if not client: return False
    try:
        sh = client.open(SHEET_NAME)
        real_code = str(sh.sheet1.acell("B1").value).strip()
        return str(input_code).strip() == real_code
    except: return False

# ==========================================
# 5. Ø§Ù„ØµÙˆØª ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
# ==========================================

# Ø¯Ø§Ù„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ù„Ù†Øµ (Ù„Ù„Ø·Ù„Ø§Ø¨)
def speech_to_text(audio_bytes):
    r = sr.Recognizer()
    try:
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨Ø§ÙŠØªØ§Øª Ø¥Ù„Ù‰ Ù…Ù„Ù ØµÙˆØªÙŠ Ù…Ø¤Ù‚Øª
        audio_file = io.BytesIO(audio_bytes.read())
        with sr.AudioFile(audio_file) as source:
            audio_data = r.record(source)
            # Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… (ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)
            text = r.recognize_google(audio_data, language="ar-EG")
            return text
    except Exception:
        return None

# Ø¯Ø§Ù„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ù„ØµÙˆØª (Ù„Ù„Ù…Ø¹Ù„Ù…)
def text_to_speech(text):
    try:
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ØµÙˆØªÙŠ Ù…Ø¤Ù‚Øª
        tts = gTTS(text=text, lang='ar', slow=False)
        # Ø­ÙØ¸Ù‡ ÙÙŠ Ø°Ø§ÙƒØ±Ø© Ù…Ø¤Ù‚ØªØ©
        fp = io.BytesIO()
        tts.write_to_fp(fp)
        return fp
    except:
        return None

def get_best_model():
    try:
        models = genai.list_models()
        chat_models = [m.name for m in models if 'generateContent' in m.supported_generation_methods]
        if not chat_models: return 'models/gemini-1.5-flash'
        for m in chat_models:
            if 'flash' in m.lower(): return m
        for m in chat_models:
            if 'pro' in m.lower() and '1.5' in m.lower(): return m
        return chat_models[0]
    except: return 'models/gemini-1.5-flash'

def get_ai_response(user_text, img_obj=None):
    try:
        keys = st.secrets.get("GOOGLE_API_KEYS", [])
        if not keys: return "âš ï¸ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù…ÙÙ‚ÙˆØ¯Ø©."
        genai.configure(api_key=random.choice(keys))
        
        u = st.session_state.user_data
        lang_prompt = "Ø§Ø´Ø±Ø­ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©." if "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" in u['lang'] else "Explain in English."
        
        # ğŸ”¥ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù„ØªÙƒÙˆÙ† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø®ØªØµØ±Ø© ÙˆÙ…Ø±ÙƒØ²Ø©
        sys_prompt = f"""
        Ø£Ù†Øª Ø§Ù„Ø£Ø³ØªØ§Ø° Ø§Ù„Ø³ÙŠØ¯ Ø§Ù„Ø¨Ø¯ÙˆÙŠ. Ø§Ù„Ø·Ø§Ù„Ø¨: {u['name']} ({u['stage']}-{u['grade']}).
        
        ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ§Ø±Ù…Ø©:
        1. Ø§Ù„ØªØ²Ù… Ø¨Ø§Ù„Ù…Ù†Ù‡Ø¬ Ø§Ù„Ù…ØµØ±ÙŠ.
        2. {lang_prompt}
        3. â›” Ù…Ù…Ù†ÙˆØ¹ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ø·ÙˆÙŠÙ„Ø©.
        4. âœ… Ø£Ø¹Ø· Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© "Ø§Ù„Ø®Ù„Ø§ØµØ© Ø§Ù„Ù…Ø®ØªØµØ±Ø© Ø§Ù„Ù…ÙÙŠØ¯Ø©" ÙÙŠ Ù†Ù‚Ø§Ø· Ù…Ø­Ø¯Ø¯Ø© (Bullet points).
        5. ÙƒÙ† Ù…Ø±Ø­Ø§Ù‹ ÙˆÙ…Ø´Ø¬Ø¹Ø§Ù‹.
        """
        
        model_name = get_best_model()
        model = genai.GenerativeModel(model_name)
        
        inputs = [sys_prompt, user_text]
        if img_obj: inputs.extend([img_obj, "Ø§Ø´Ø±Ø­ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø®ØªØµØ§Ø±."])
        
        return model.generate_content(inputs).text
    except Exception as e: return f"Ø®Ø·Ø£: {e}"

# ==========================================
# 6. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø§Øª ÙˆØ§Ù„ØªØ´ØºÙŠÙ„
# ==========================================
def login_page():
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.markdown("### ğŸ” ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„")
        with st.form("login"):
            name = st.text_input("Ø§Ù„Ø§Ø³Ù…")
            code = st.text_input("Ø§Ù„ÙƒÙˆØ¯", type="password")
            st.markdown("---")
            c1, c2 = st.columns(2)
            with c1:
                stage = st.selectbox("Ø§Ù„Ù…Ø±Ø­Ù„Ø©", ["Ø§Ù„Ø§Ø¨ØªØ¯Ø§Ø¦ÙŠØ©", "Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ÙŠØ©", "Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©"])
                lang = st.selectbox("Ø§Ù„Ù„ØºØ©", ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"])
            with c2:
                grade = st.selectbox("Ø§Ù„ØµÙ", ["Ø§Ù„Ø±Ø§Ø¨Ø¹", "Ø§Ù„Ø®Ø§Ù…Ø³", "Ø§Ù„Ø³Ø§Ø¯Ø³", "Ø§Ù„Ø£ÙˆÙ„", "Ø§Ù„Ø«Ø§Ù†ÙŠ", "Ø§Ù„Ø«Ø§Ù„Ø«"])
            
            if st.form_submit_button("Ø¯Ø®ÙˆÙ„"):
                if code == TEACHER_KEY:
                    st.session_state.user_data.update({"logged_in": True, "role": "Teacher", "name": name})
                    st.rerun()
                elif check_student_code(code):
                    st.session_state.user_data.update({"logged_in": True, "role": "Student", "name": name, "stage": stage, "grade": grade, "lang": lang})
                    st.rerun()
                else:
                    st.error("Ø§Ù„ÙƒÙˆØ¯ Ø®Ø·Ø£")

def main_app():
    with st.sidebar:
        st.success(f"Ù…Ø±Ø­Ø¨Ø§Ù‹: {st.session_state.user_data['name']}")
        if st.button("Ø®Ø±ÙˆØ¬"):
            st.session_state.user_data["logged_in"] = False
            st.rerun()

    st.subheader("ğŸ’¬ Ø§Ø³Ø£Ù„ Ø§Ù„Ù…Ø¹Ù„Ù… (ØµÙˆØª Ø£Ùˆ ÙƒØªØ§Ø¨Ø©)")
    
    # 1. Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†
    col_mic, col_cam = st.columns([1, 1])
    with col_mic:
        st.write("ğŸ™ï¸ Ø§Ø¶ØºØ· Ù„Ù„ØªØ­Ø¯Ø«:")
        audio = mic_recorder(start_prompt="Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ³Ø¬ÙŠÙ„", stop_prompt="ØªÙˆÙ‚Ù", key='recorder')
    
    with col_cam:
        with st.expander("ğŸ“¸ Ø¥Ø±ÙØ§Ù‚ ØµÙˆØ±Ø©"):
            f = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø©", type=['jpg', 'png'])
            img = Image.open(f) if f else None
            if img: st.image(img, width=150)

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø³Ø¬Ù„
    user_input = None
    if audio:
        with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­ÙˆÙŠÙ„ ØµÙˆØªÙƒ Ù„Ù†Øµ..."):
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨Ø§ÙŠØªØ§Øª Ø¥Ù„Ù‰ ÙƒØ§Ø¦Ù† Ù‚Ø§Ø¨Ù„ Ù„Ù„Ù‚Ø±Ø§Ø¡Ø©
            audio_bio = io.BytesIO(audio['bytes'])
            audio_bio.name = 'audio.wav'
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… SpeechRecognition
            r = sr.Recognizer()
            try:
                with sr.AudioFile(audio_bio) as source:
                    audio_data = r.record(source)
                    user_input = r.recognize_google(audio_data, language="ar-EG")
            except:
                st.warning("Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø³Ù…Ø§Ø¹Ùƒ Ø¨ÙˆØ¶ÙˆØ­ØŒ Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")

    # 2. Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])
            # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ù„Ù…ØŒ Ù†Ø¹Ø±Ø¶ Ø²Ø± ØªØ´ØºÙŠÙ„ Ø§Ù„ØµÙˆØª Ø§Ù„Ù‚Ø¯ÙŠÙ… (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)

    # 3. Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª (ÙƒØªØ§Ø¨Ø© Ø£Ùˆ ØµÙˆØª)
    prompt = st.chat_input("Ø£Ùˆ Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§...")
    
    # ØªØ­Ø¯ÙŠØ¯ Ù…ØµØ¯Ø± Ø§Ù„Ø³Ø¤Ø§Ù„ (ÙƒØªØ§Ø¨Ø© Ø£Ù… ØµÙˆØª)
    final_prompt = prompt if prompt else user_input

    if final_prompt:
        # Ø¹Ø±Ø¶ Ø³Ø¤Ø§Ù„ Ø§Ù„Ø·Ø§Ù„Ø¨
        st.session_state.messages.append({"role": "user", "content": final_prompt})
        with st.chat_message("user"): st.write(final_prompt)
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¯
        with st.chat_message("assistant"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ±..."):
                resp_text = get_ai_response(final_prompt, img)
                st.write(resp_text)
                
                # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø©
                audio_fp = text_to_speech(resp_text)
                if audio_fp:
                    st.audio(audio_fp, format='audio/mp3')
        
        st.session_state.messages.append({"role": "assistant", "content": resp_text})

if __name__ == "__main__":
    if st.session_state.user_data["logged_in"]:
        main_app()
    else:
        login_page()
