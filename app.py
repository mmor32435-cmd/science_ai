import streamlit as st
from google.oauth2 import service_account
import google.generativeai as genai
import gspread
from PIL import Image
import random
import speech_recognition as sr
from streamlit_mic_recorder import mic_recorder
import asyncio
import edge_tts
import tempfile
import os
import re

# ==========================================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
# ==========================================
st.set_page_config(
    page_title="Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø¹Ù„Ù…ÙŠ | Ø§Ù„Ø³ÙŠØ¯ Ø§Ù„Ø¨Ø¯ÙˆÙŠ",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==========================================
# 2. ØªØµÙ…ÙŠÙ… Ø¹Ø§Ù„ÙŠ Ø§Ù„ØªØ¨Ø§ÙŠÙ† (Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø£Ù„ÙˆØ§Ù†)
# ==========================================
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
    
    /* 1. ØªØ¹Ù…ÙŠÙ… Ø§Ù„Ø®Ø· ÙˆØ§Ù„Ø§ØªØ¬Ø§Ù‡ ÙˆØ§Ù„Ù„ÙˆÙ† Ø§Ù„Ø£Ø³ÙˆØ¯ */
    html, body, [class*="css"], div, p, span, h1, h2, h3 {
        font-family: 'Cairo', sans-serif !important;
        direction: rtl;
        text-align: right;
    }
    
    /* 2. Ø®Ù„ÙÙŠØ© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ */
    .stApp {
        background-color: #f4f6f9;
    }
    
    /* 3. Ø¥ØµÙ„Ø§Ø­ Ø¬Ø°Ø±ÙŠ Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø´Ø§Øª (Ø£Ø³ÙˆØ¯ Ø¹Ù„Ù‰ Ø®Ù„ÙÙŠØ© ÙØ§ØªØ­Ø©) */
    .stChatMessage {
        background-color: #ffffff !important;
        border: 1px solid #d1d1d1 !important;
        border-radius: 12px !important;
        padding: 15px !important;
        box-shadow: 0 2px 5px rgba(0,0,0,0.1) !important;
    }
    
    /* Ø¥Ø¬Ø¨Ø§Ø± Ø§Ù„Ù†Øµ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø´Ø§Øª Ø£Ù† ÙŠÙƒÙˆÙ† Ø£Ø³ÙˆØ¯ */
    div[data-testid="stMarkdownContainer"] p {
        color: #000000 !important;
        font-size: 18px !important;
        line-height: 1.6 !important;
    }
    
    /* 4. Ø¥ØµÙ„Ø§Ø­ Ø£Ù„ÙˆØ§Ù† Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ */
    .stTextInput input, .stTextArea textarea {
        color: #000000 !important;
        background-color: #ffffff !important;
        border: 1px solid #004e92 !important;
    }
    
    /* 5. ØµÙ†Ø¯ÙˆÙ‚ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† */
    .header-box {
        background: linear-gradient(90deg, #141E30 0%, #243B55 100%);
        padding: 2rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        text-align: center;
    }
    .header-box h1, .header-box h3 { color: #ffffff !important; }

    /* 6. Ø§Ù„Ø£Ø²Ø±Ø§Ø± */
    .stButton>button {
        background-color: #004e92;
        color: #ffffff !important;
        border-radius: 10px;
        height: 50px;
        font-size: 18px;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# Ø¨Ø§Ù†Ø± Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
st.markdown("""
<div class="header-box">
    <h1>Ø§Ù„Ø£Ø³ØªØ§Ø° / Ø§Ù„Ø³ÙŠØ¯ Ø§Ù„Ø¨Ø¯ÙˆÙŠ</h1>
    <h3>Mr. Elsayed Elbadawy - Expert Science Tutor</h3>
</div>
""", unsafe_allow_html=True)

# ==========================================
# 3. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¬Ù„Ø³Ø©
# ==========================================
if 'user_data' not in st.session_state:
    st.session_state.user_data = {
        "logged_in": False, "role": None, "name": "", "grade": "", "stage": "", "lang": ""
    }
if 'messages' not in st.session_state: st.session_state.messages = []

# ==========================================
# 4. Ø¯ÙˆØ§Ù„ Ø§Ù„Ø§ØªØµØ§Ù„
# ==========================================
TEACHER_KEY = st.secrets.get("TEACHER_MASTER_KEY", "ADMIN")
SHEET_NAME = st.secrets.get("CONTROL_SHEET_NAME", "App_Control")

@st.cache_resource
def get_gspread_client():
    if "gcp_service_account" not in st.secrets: return None
    try:
        creds_dict = dict(st.secrets["gcp_service_account"])
        if "private_key" in creds_dict:
            creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
        scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
        creds = service_account.Credentials.from_service_account_info(creds_dict, scopes=scopes)
        return gspread.authorize(creds)
    except: return None

def check_student_code(input_code):
    client = get_gspread_client()
    if not client: return False
    try:
        sh = client.open(SHEET_NAME)
        real_code = str(sh.sheet1.acell("B1").value).strip()
        return str(input_code).strip() == real_code
    except: return False

# ==========================================
# 5. Ø§Ù„ØµÙˆØª ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ (ØªÙ… Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†)
# ==========================================

def clean_text_for_speech(text):
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ù…Ø²Ø¹Ø¬Ø© Ø¹Ù†Ø¯ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©
    text = re.sub(r'[\*\#\-\_]', '', text)
    return text

def speech_to_text(audio_bytes):
    r = sr.Recognizer()
    try:
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(audio_bytes)
            tmp_filename = tmp_file.name
        
        with sr.AudioFile(tmp_filename) as source:
            # â›” ØªÙ… Ø¥Ø²Ø§Ù„Ø© (adjust_for_ambient_noise) Ù„Ø£Ù†Ù‡Ø§ ÙƒØ§Ù†Øª ØªØ­Ø°Ù Ø§Ù„ØµÙˆØª Ø§Ù„Ù‚ØµÙŠØ±
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØª Ù…Ø¨Ø§Ø´Ø±Ø©
            audio_data = r.record(source)
            text = r.recognize_google(audio_data, language="ar-EG")
        
        os.remove(tmp_filename)
        return text
    except:
        return None

async def generate_speech_async(text, voice="ar-EG-ShakirNeural"):
    cleaned_text = clean_text_for_speech(text)
    communicate = edge_tts.Communicate(cleaned_text, voice)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
        await communicate.save(tmp_file.name)
        return tmp_file.name

def text_to_speech_pro(text):
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        return loop.run_until_complete(generate_speech_async(text))
    except: return None

def get_best_model():
    try:
        models = genai.list_models()
        chat_models = [m.name for m in models if 'generateContent' in m.supported_generation_methods]
        if not chat_models: return 'models/gemini-1.5-flash'
        for m in chat_models:
            if 'flash' in m.lower(): return m
        return chat_models[0]
    except: return 'models/gemini-1.5-flash'

def get_ai_response(user_text, img_obj=None):
    try:
        keys = st.secrets.get("GOOGLE_API_KEYS", [])
        if not keys: return "âš ï¸ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù…ÙÙ‚ÙˆØ¯Ø©."
        genai.configure(api_key=random.choice(keys))
        
        u = st.session_state.user_data
        lang_prompt = "Ø§Ø´Ø±Ø­ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©." if "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" in u['lang'] else "Explain in English."
        
        sys_prompt = f"""
        Ø£Ù†Øª Ø§Ù„Ø£Ø³ØªØ§Ø° Ø§Ù„Ø³ÙŠØ¯ Ø§Ù„Ø¨Ø¯ÙˆÙŠ. Ø§Ù„Ø·Ø§Ù„Ø¨: {u['name']} ({u['stage']}-{u['grade']}).
        1. Ø§Ù„ØªØ²Ù… Ø¨Ø§Ù„Ù…Ù†Ù‡Ø¬.
        2. {lang_prompt}
        3. ÙƒÙ† Ù…Ø®ØªØµØ±Ø§Ù‹ ÙˆÙ…ÙÙŠØ¯Ø§Ù‹ (Brief Summary).
        4. Ø§Ø³ØªØ®Ø¯Ù… Ù†Ù‚Ø§Ø· (Bullet points).
        """
        
        model_name = get_best_model()
        model = genai.GenerativeModel(model_name)
        
        inputs = [sys_prompt, user_text]
        if img_obj: inputs.extend([img_obj, "Ø§Ø´Ø±Ø­ Ø§Ù„ØµÙˆØ±Ø©."])
        
        return model.generate_content(inputs).text
    except Exception as e: return f"Ø®Ø·Ø£: {e}"

# ==========================================
# 6. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø§Øª ÙˆØ§Ù„ØªØ´ØºÙŠÙ„
# ==========================================
def login_page():
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.markdown("### ğŸ” ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„")
        with st.form("login"):
            name = st.text_input("Ø§Ù„Ø§Ø³Ù…")
            code = st.text_input("Ø§Ù„ÙƒÙˆØ¯", type="password")
            st.markdown("---")
            c1, c2 = st.columns(2)
            with c1:
                stage = st.selectbox("Ø§Ù„Ù…Ø±Ø­Ù„Ø©", ["Ø§Ù„Ø§Ø¨ØªØ¯Ø§Ø¦ÙŠØ©", "Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ÙŠØ©", "Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©"])
                lang = st.selectbox("Ø§Ù„Ù„ØºØ©", ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"])
            with c2:
                grade = st.selectbox("Ø§Ù„ØµÙ", ["Ø§Ù„Ø±Ø§Ø¨Ø¹", "Ø§Ù„Ø®Ø§Ù…Ø³", "Ø§Ù„Ø³Ø§Ø¯Ø³", "Ø§Ù„Ø£ÙˆÙ„", "Ø§Ù„Ø«Ø§Ù†ÙŠ", "Ø§Ù„Ø«Ø§Ù„Ø«"])
            
            if st.form_submit_button("Ø¯Ø®ÙˆÙ„"):
                if code == TEACHER_KEY:
                    st.session_state.user_data.update({"logged_in": True, "role": "Teacher", "name": name})
                    st.rerun()
                elif check_student_code(code):
                    st.session_state.user_data.update({"logged_in": True, "role": "Student", "name": name, "stage": stage, "grade": grade, "lang": lang})
                    st.rerun()
                else:
                    st.error("Ø§Ù„ÙƒÙˆØ¯ Ø®Ø·Ø£")

def main_app():
    with st.sidebar:
        st.success(f"Ù…Ø±Ø­Ø¨Ø§Ù‹: {st.session_state.user_data['name']}")
        if st.button("Ø®Ø±ÙˆØ¬"):
            st.session_state.user_data["logged_in"] = False
            st.rerun()

    st.subheader("ğŸ’¬ Ø§Ø³Ø£Ù„ Ø§Ù„Ù…Ø¹Ù„Ù… (ØªØ­Ø¯Ø« Ø£Ùˆ Ø§ÙƒØªØ¨)")
    
    # Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† ÙˆØ§Ù„ØµÙˆØ±
    c_mic, c_img = st.columns([1, 1])
    with c_mic:
        st.info("ğŸ™ï¸ Ø§Ø¶ØºØ· Ù„Ù„ØªØ­Ø¯Ø«ØŒ ÙˆØ§Ø¶ØºØ· Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù„Ù„Ø¥Ø±Ø³Ø§Ù„:")
        audio = mic_recorder(start_prompt="Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ âºï¸", stop_prompt="Ø¥Ø±Ø³Ø§Ù„ â¹ï¸", key='recorder')
    
    with c_img:
        with st.expander("ğŸ“¸ Ø¥Ø±ÙØ§Ù‚ ØµÙˆØ±Ø©"):
            f = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø©", type=['jpg', 'png'])
            img = Image.open(f) if f else None
            if img: st.image(img, width=150)

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª
    voice_text = None
    if audio:
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª..."):
            voice_text = speech_to_text(audio['bytes'])
            if not voice_text:
                st.warning("âš ï¸ Ø§Ù„ØµÙˆØª ØºÙŠØ± ÙˆØ§Ø¶Ø­.")

    # Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© (ØªÙ… Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ù‡Ù†Ø§)
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    # Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†ØµÙŠ
    text_input = st.chat_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ...")
    final_q = text_input if text_input else voice_text

    if final_q:
        st.session_state.messages.append({"role": "user", "content": final_q})
        with st.chat_message("user"): st.write(final_q)
        
        with st.chat_message("assistant"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ø¶ÙŠØ±..."):
                resp_text = get_ai_response(final_q, img)
                st.write(resp_text)
                
                audio_file = text_to_speech_pro(resp_text)
                if audio_file:
                    st.audio(audio_file, format='audio/mp3')
        
        st.session_state.messages.append({"role": "assistant", "content": resp_text})

if __name__ == "__main__":
    if st.session_state.user_data["logged_in"]:
        main_app()
    else:
        login_page()
