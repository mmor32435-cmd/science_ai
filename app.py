import streamlit as st
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
import google.generativeai as genai
import gspread
from PIL import Image
import random
import speech_recognition as sr
from streamlit_mic_recorder import mic_recorder
import asyncio
import edge_tts
import tempfile
import os
import re
import io
import PyPDF2

# ==========================================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
# ==========================================
st.set_page_config(
    page_title="Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø¹Ù„Ù…ÙŠ | Ø§Ù„Ø³ÙŠØ¯ Ø§Ù„Ø¨Ø¯ÙˆÙŠ",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==========================================
# 2. ØªØµÙ…ÙŠÙ… Ø¹Ø§Ù„ÙŠ Ø§Ù„ØªØ¨Ø§ÙŠÙ† (Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø¬Ø°Ø±ÙŠØ§Ù‹)
# ==========================================
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
    
    /* ØªØ¹Ù…ÙŠÙ… Ø§Ù„Ø®Ø· */
    html, body, [class*="css"] {
        font-family: 'Cairo', sans-serif !important;
        direction: rtl;
        text-align: right;
    }
    
    /* Ø®Ù„ÙÙŠØ© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ */
    .stApp {
        background-color: #f0f2f6;
    }
    
    /* --- Ø¥ØµÙ„Ø§Ø­ Ø£Ù„ÙˆØ§Ù† Ø§Ù„ÙƒØªØ§Ø¨Ø© (Ø£Ø³ÙˆØ¯ Ø¯Ø§ÙƒÙ†) --- */
    .stTextInput input, .stTextArea textarea, .stSelectbox div, .stNumberInput input {
        color: #000000 !important; /* Ø§Ù„Ù†Øµ Ø£Ø³ÙˆØ¯ */
        background-color: #ffffff !important; /* Ø§Ù„Ø®Ù„ÙÙŠØ© Ø¨ÙŠØ¶Ø§Ø¡ */
        font-weight: bold !important;
        border: 1px solid #aaa !important;
    }
    
    /* Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ù…Ù†Ø³Ø¯Ù„Ø© */
    div[data-baseweb="select"] > div {
        background-color: #ffffff !important;
        color: #000000 !important;
    }
    
    /* Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù†ØµÙˆØµ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø£ÙŠÙ‚ÙˆÙ†Ø§Øª ÙˆØ§Ù„Ø£Ø²Ø±Ø§Ø± */
    .stButton>button {
        background-color: #004e92 !important;
        color: #ffffff !important;
        border-radius: 8px;
        height: 50px;
        font-size: 18px !important;
        font-weight: bold !important;
    }
    
    /* Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø´Ø§Øª */
    .stChatMessage {
        background-color: #ffffff !important;
        border: 1px solid #ccc !important;
        color: #000000 !important;
    }
    div[data-testid="stMarkdownContainer"] p {
        color: #000000 !important;
    }

    /* Ø§Ù„Ø¹Ù†ÙˆØ§Ù† */
    .header-box {
        background: linear-gradient(90deg, #141E30 0%, #243B55 100%);
        padding: 2rem; border-radius: 15px; margin-bottom: 2rem; text-align: center;
    }
    .header-box h1, .header-box h3 { color: #ffffff !important; }
</style>
""", unsafe_allow_html=True)

st.markdown("""
<div class="header-box">
    <h1>Ø§Ù„Ø£Ø³ØªØ§Ø° / Ø§Ù„Ø³ÙŠØ¯ Ø§Ù„Ø¨Ø¯ÙˆÙŠ</h1>
    <h3>Ø§Ù„Ù…Ù†ØµØ© Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ø§Ù„Ø°ÙƒÙŠØ©</h3>
</div>
""", unsafe_allow_html=True)

# ==========================================
# 3. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¬Ù„Ø³Ø©
# ==========================================
if 'user_data' not in st.session_state:
    st.session_state.user_data = {"logged_in": False, "role": None, "name": "", "grade": "", "stage": "", "lang": ""}
if 'messages' not in st.session_state: st.session_state.messages = []
if 'book_content' not in st.session_state: st.session_state.book_content = ""

# ==========================================
# 4. Ø§Ù„Ø§ØªØµØ§Ù„ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ==========================================
TEACHER_KEY = st.secrets.get("TEACHER_MASTER_KEY", "ADMIN")
SHEET_NAME = st.secrets.get("CONTROL_SHEET_NAME", "App_Control")

@st.cache_resource
def get_credentials():
    if "gcp_service_account" not in st.secrets: return None
    try:
        creds_dict = dict(st.secrets["gcp_service_account"])
        if "private_key" in creds_dict:
            creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
        scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
        return service_account.Credentials.from_service_account_info(creds_dict, scopes=scopes)
    except: return None

def get_gspread_client():
    creds = get_credentials()
    return gspread.authorize(creds) if creds else None

def check_student_code(input_code):
    client = get_gspread_client()
    if not client: return False
    try:
        sh = client.open(SHEET_NAME)
        real_code = str(sh.sheet1.acell("B1").value).strip()
        return str(input_code).strip() == real_code
    except: return False

@st.cache_resource
def get_book_text_from_drive(grade, lang):
    creds = get_credentials()
    if not creds: return None
    try:
        grade_map = {"Ø§Ù„Ø±Ø§Ø¨Ø¹": "Grade4", "Ø§Ù„Ø®Ø§Ù…Ø³": "Grade5", "Ø§Ù„Ø³Ø§Ø¯Ø³": "Grade6", "Ø§Ù„Ø£ÙˆÙ„": "Prep1", "Ø§Ù„Ø«Ø§Ù†ÙŠ": "Prep2", "Ø§Ù„Ø«Ø§Ù„Ø«": "Prep3"}
        lang_code = "Ar" if "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" in lang else "En"
        file_prefix = grade_map.get(grade, "Grade4")
        expected_name = f"{file_prefix}_{lang_code}"
        
        service = build('drive', 'v3', credentials=creds)
        results = service.files().list(q=f"name contains '{expected_name}' and mimeType='application/pdf'", fields="files(id, name)").execute()
        files = results.get('files', [])
        
        if not files: return None
        request = service.files().get_media(fileId=files[0]['id'])
        file_stream = io.BytesIO()
        downloader = MediaIoBaseDownload(file_stream, request)
        done = False
        while done is False: status, done = downloader.next_chunk()
        
        file_stream.seek(0)
        pdf_reader = PyPDF2.PdfReader(file_stream)
        text = ""
        for page in pdf_reader.pages[:50]: text += page.extract_text() + "\n"
        return text
    except: return None

# ==========================================
# 5. Ø§Ù„ØµÙˆØª ÙˆØ§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† (ØªÙ… Ø§Ù„Ø¥ØµÙ„Ø§Ø­)
# ==========================================
def clean_text_for_speech(text):
    text = re.sub(r'[\*\#\-\_]', '', text)
    return text

def speech_to_text(audio_bytes):
    r = sr.Recognizer()
    try:
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… BytesIO Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ø¹ ØµÙŠØºØ© wav
        audio_io = io.BytesIO(audio_bytes)
        with sr.AudioFile(audio_io) as source:
            # ØªÙ… Ø¥Ø²Ø§Ù„Ø© calibration Ù„Ø£Ù†Ù‡ ÙŠØ³Ø¨Ø¨ Ù…Ø´Ø§ÙƒÙ„
            audio_data = r.record(source)
            text = r.recognize_google(audio_data, language="ar-EG")
            return text
    except: return None

async def generate_speech_async(text, voice="ar-EG-ShakirNeural"):
    cleaned = clean_text_for_speech(text)
    communicate = edge_tts.Communicate(cleaned, voice)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
        await communicate.save(tmp_file.name)
        return tmp_file.name

def text_to_speech_pro(text):
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        return loop.run_until_complete(generate_speech_async(text))
    except: return None

# ==========================================
# 6. Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„)
# ==========================================

def get_dynamic_model():
    """
    Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© ØªØ·Ø¨Ù‚ Ø·Ù„Ø¨Ùƒ Ø­Ø±ÙÙŠØ§Ù‹:
    Ù„Ø§ ØªØ¶Ø¹ Ø§Ø³Ù… Ù…ÙˆØ¯ÙŠÙ„ Ø«Ø§Ø¨ØªØŒ Ø¨Ù„ Ø§Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ÙˆØ§Ø®ØªØ± Ø§Ù„Ù…ØªØ§Ø­.
    """
    try:
        # Ø¬Ù„Ø¨ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
        all_models = genai.list_models()
        
        # ØªØµÙÙŠØ© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙŠ ØªØ¯Ø¹Ù… Ø§Ù„Ø´Ø§Øª
        valid_models = []
        for m in all_models:
            if 'generateContent' in m.supported_generation_methods:
                valid_models.append(m.name)
        
        if not valid_models:
            # Ø­Ø§Ù„Ø© Ù†Ø§Ø¯Ø±Ø© Ø¬Ø¯Ø§Ù‹: Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø£ÙŠ Ù…ÙˆØ¯ÙŠÙ„ Ù…ØªØ§Ø­
            return None
        
        # Ø§Ù„ØªÙØ¶ÙŠÙ„: Ù†Ø¨Ø­Ø« Ø¹Ù† Flash Ø£ÙˆÙ„Ø§Ù‹ØŒ Ø«Ù… ProØŒ Ø«Ù… Ø£ÙŠ Ø´ÙŠØ¡
        for m in valid_models:
            if 'flash' in m.lower(): return m
        
        for m in valid_models:
            if 'pro' in m.lower(): return m
            
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø§Ù„Ù…ÙØ¶Ù„Ø§ØªØŒ Ù†Ø£Ø®Ø° Ø£ÙˆÙ„ ÙˆØ§Ø­Ø¯ ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø£ÙŠØ§Ù‹ ÙƒØ§Ù† Ø§Ø³Ù…Ù‡
        return valid_models[0]
        
    except Exception as e:
        return None

def get_ai_response(user_text, img_obj=None, is_quiz_mode=False):
    keys = st.secrets.get("GOOGLE_API_KEYS", [])
    if not keys: return "âš ï¸ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù…ÙÙ‚ÙˆØ¯Ø©."
    genai.configure(api_key=random.choice(keys))
    
    # ğŸ”¥ Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„Ø­Ø§Ø³Ù…Ø©: Ø¬Ù„Ø¨ Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…ØªØ§Ø­ ÙØ¹Ù„ÙŠØ§Ù‹ ğŸ”¥
    model_name = get_dynamic_model()
    if not model_name:
        return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†Ù…Ø§Ø°Ø¬ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…ØªØ§Ø­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹ ÙÙŠ Ø­Ø³Ø§Ø¨Ùƒ."
    
    u = st.session_state.user_data
    if not st.session_state.book_content:
        book_text = get_book_text_from_drive(u['grade'], u['lang'])
        if book_text: st.session_state.book_content = book_text

    lang_prompt = "Ø§Ø´Ø±Ø­ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©." if "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" in u['lang'] else "Explain in English."
    context = ""
    if st.session_state.book_content:
        context = f"Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ø§ Ø§Ù„ÙƒØªØ§Ø¨ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø©:\n{st.session_state.book_content[:30000]}..."
    
    quiz_instr = "Ø£Ù†Ø´Ø¦ Ø³Ø¤Ø§Ù„Ø§Ù‹ ÙˆØ§Ø­Ø¯Ø§Ù‹ ÙÙ‚Ø·." if is_quiz_mode else ""
    
    sys_prompt = f"""
    Ø£Ù†Øª Ø§Ù„Ø£Ø³ØªØ§Ø° Ø§Ù„Ø³ÙŠØ¯ Ø§Ù„Ø¨Ø¯ÙˆÙŠ.
    {context}
    1. Ø§Ù„ØªØ²Ù… Ø¨Ø§Ù„Ù…Ù†Ù‡Ø¬.
    2. {lang_prompt}
    3. ÙƒÙ† Ù…Ø®ØªØµØ±Ø§Ù‹ (Ù†Ù‚Ø§Ø·).
    4. {quiz_instr}
    """
    
    inputs = [sys_prompt, user_text]
    if img_obj: inputs.extend([img_obj, "Ø§Ø´Ø±Ø­ Ø§Ù„ØµÙˆØ±Ø©."])

    try:
        model = genai.GenerativeModel(model_name)
        return model.generate_content(inputs).text
    except Exception as e:
        return f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ({model_name}): {e}"

# ==========================================
# 7. Ø§Ù„ØªØ´ØºÙŠÙ„ ÙˆØ§Ù„ÙˆØ§Ø¬Ù‡Ø§Øª
# ==========================================
def celebrate_success():
    st.balloons()
    st.toast("ğŸŒŸ Ù…Ù…ØªØ§Ø²!", icon="ğŸ‰")

def login_page():
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.markdown("### ğŸ” ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„")
        with st.form("login"):
            name = st.text_input("Ø§Ù„Ø§Ø³Ù…")
            code = st.text_input("Ø§Ù„ÙƒÙˆØ¯", type="password")
            st.markdown("---")
            c1, c2 = st.columns(2)
            with c1:
                stage = st.selectbox("Ø§Ù„Ù…Ø±Ø­Ù„Ø©", ["Ø§Ù„Ø§Ø¨ØªØ¯Ø§Ø¦ÙŠØ©", "Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ÙŠØ©"])
                lang = st.selectbox("Ø§Ù„Ù„ØºØ©", ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (Ø¹Ù„ÙˆÙ…)", "English (Science)"])
            with c2:
                grade = st.selectbox("Ø§Ù„ØµÙ", ["Ø§Ù„Ø±Ø§Ø¨Ø¹", "Ø§Ù„Ø®Ø§Ù…Ø³", "Ø§Ù„Ø³Ø§Ø¯Ø³", "Ø§Ù„Ø£ÙˆÙ„", "Ø§Ù„Ø«Ø§Ù†ÙŠ", "Ø§Ù„Ø«Ø§Ù„Ø«"])
            
            if st.form_submit_button("Ø¯Ø®ÙˆÙ„"):
                if code == TEACHER_KEY:
                    st.session_state.user_data.update({"logged_in": True, "role": "Teacher", "name": name})
                    st.rerun()
                elif check_student_code(code):
                    st.session_state.user_data.update({"logged_in": True, "role": "Student", "name": name, "stage": stage, "grade": grade, "lang": lang})
                    st.session_state.book_content = ""
                    st.rerun()
                else:
                    st.error("Ø§Ù„ÙƒÙˆØ¯ Ø®Ø·Ø£")

def main_app():
    with st.sidebar:
        st.success(f"Ù…Ø±Ø­Ø¨Ø§Ù‹: {st.session_state.user_data['name']}")
        if st.button("ğŸ“ Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±ÙŠØ¹"):
             st.session_state.messages.append({"role": "user", "content": "Ø£Ø±ÙŠØ¯ Ø³Ø¤Ø§Ù„ Ø§Ø®ØªØ¨Ø§Ø±."})
        if st.button("ğŸšª Ø®Ø±ÙˆØ¬"):
            st.session_state.user_data["logged_in"] = False
            st.rerun()

    st.subheader("ğŸ’¬ Ø§Ø³Ø£Ù„ Ø§Ù„Ù…Ø¹Ù„Ù…")
    
    c_mic, c_img = st.columns([1, 1])
    with c_mic:
        st.info("ğŸ™ï¸ Ø§Ø¶ØºØ· Ù„Ù„ØªØ­Ø¯Ø«:")
        # Ø¶Ø¨Ø· Ø§Ù„ØµÙŠØºØ© Ø¹Ù„Ù‰ wav Ù„Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†
        audio = mic_recorder(start_prompt="ØªØ³Ø¬ÙŠÙ„ âºï¸", stop_prompt="Ø¥Ø±Ø³Ø§Ù„ â¹ï¸", key='recorder', format='wav')
    
    with c_img:
        with st.expander("ğŸ“¸ Ø¥Ø±ÙØ§Ù‚ ØµÙˆØ±Ø©"):
            f = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø©", type=['jpg', 'png'])
            img = Image.open(f) if f else None
            if img: st.image(img, width=150)

    voice_text = None
    if audio:
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø³Ù…Ø§Ø¹Ùƒ..."):
            voice_text = speech_to_text(audio['bytes'])
            if not voice_text: st.warning("âš ï¸ Ø§Ù„ØµÙˆØª ØºÙŠØ± ÙˆØ§Ø¶Ø­.")

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]): st.write(msg["content"])

    text_input = st.chat_input("Ø§ÙƒØªØ¨ Ù‡Ù†Ø§...")
    final_q = text_input if text_input else voice_text

    if final_q:
        st.session_state.messages.append({"role": "user", "content": final_q})
        with st.chat_message("user"): st.write(final_q)
        
        with st.chat_message("assistant"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ø¶ÙŠØ±..."):
                is_quiz = "Ø§Ø®ØªØ¨Ø§Ø±" in final_q or "Ø³Ø¤Ø§Ù„" in final_q
                resp_text = get_ai_response(final_q, img, is_quiz_mode=is_quiz)
                st.write(resp_text)
                
                if any(w in resp_text for w in ["Ø£Ø­Ø³Ù†Øª", "Ù…Ù…ØªØ§Ø²", "Ø±Ø§Ø¦Ø¹"]): celebrate_success()
                
                audio_file = text_to_speech_pro(resp_text)
                if audio_file: st.audio(audio_file, format='audio/mp3')
        
        st.session_state.messages.append({"role": "assistant", "content": resp_text})

if __name__ == "__main__":
    if st.session_state.user_data["logged_in"]:
        main_app()
    else:
        login_page()
