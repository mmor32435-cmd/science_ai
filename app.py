import streamlit as st
from google.oauth2 import service_account
import google.generativeai as genai
import gspread
from PIL import Image
import random
import speech_recognition as sr
from streamlit_mic_recorder import mic_recorder
import asyncio
import edge_tts
import tempfile
import os
import re # Ù…ÙƒØªØ¨Ø© Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù†ØµÙˆØµ ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ²

# ==========================================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
# ==========================================
st.set_page_config(
    page_title="Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø¹Ù„Ù…ÙŠ | Ø§Ù„Ø³ÙŠØ¯ Ø§Ù„Ø¨Ø¯ÙˆÙŠ",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==========================================
# 2. ØªØµÙ…ÙŠÙ… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© (Ø¥ØµÙ„Ø§Ø­ Ø£Ù„ÙˆØ§Ù† Ø§Ù„ÙƒØªØ§Ø¨Ø©)
# ==========================================
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
    
    html, body, [class*="css"] {
        font-family: 'Cairo', sans-serif;
        direction: rtl;
        text-align: right;
    }
    
    /* Ø®Ù„ÙÙŠØ© Ø²Ø±Ù‚Ø§Ø¡ ÙØ§ØªØ­Ø© Ù…Ø±ÙŠØ­Ø© Ù„Ù„Ø¹ÙŠÙ† */
    .stApp {
        background-color: #f0f8ff;
    }
    
    /* ØµÙ†Ø¯ÙˆÙ‚ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† */
    .header-box {
        background: linear-gradient(90deg, #0f2027 0%, #203a43 50%, #2c5364 100%);
        padding: 2rem;
        border-radius: 15px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 4px 10px rgba(0,0,0,0.3);
    }
    
    /* Ø¥ØµÙ„Ø§Ø­ Ø¬Ø°Ø±ÙŠ Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ø®ØªÙØ§Ø¡ Ø§Ù„ÙƒØªØ§Ø¨Ø© */
    /* Ù†Ø¬Ø¨Ø± Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø£Ù† ØªÙƒÙˆÙ† Ø¨ÙŠØ¶Ø§Ø¡ ÙˆØ§Ù„Ù†Øµ Ø£Ø³ÙˆØ¯ */
    .stTextInput input {
        color: #000000 !important;
        background-color: #ffffff !important;
        border: 1px solid #ccc;
    }
    .stSelectbox div[data-baseweb="select"] > div {
        color: #000000 !important;
        background-color: #ffffff !important;
    }
    
    /* Ø§Ù„Ø£Ø²Ø±Ø§Ø± */
    .stButton>button {
        background-color: #2c5364;
        color: white !important;
        border-radius: 8px;
        height: 50px;
        width: 100%;
        font-size: 18px;
        font-weight: bold;
    }
    
    /* Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø´Ø§Øª */
    .stChatMessage {
        background-color: #ffffff;
        border: 1px solid #e0e0e0;
        color: #000000;
    }
</style>
""", unsafe_allow_html=True)

st.markdown("""
<div class="header-box">
    <h1>Ø§Ù„Ø£Ø³ØªØ§Ø° / Ø§Ù„Ø³ÙŠØ¯ Ø§Ù„Ø¨Ø¯ÙˆÙŠ</h1>
    <h3>Mr. Elsayed Elbadawy - Expert Science Tutor</h3>
</div>
""", unsafe_allow_html=True)

# ==========================================
# 3. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¬Ù„Ø³Ø©
# ==========================================
if 'user_data' not in st.session_state:
    st.session_state.user_data = {
        "logged_in": False, "role": None, "name": "", "grade": "", "stage": "", "lang": ""
    }
if 'messages' not in st.session_state: st.session_state.messages = []

# ==========================================
# 4. Ø¯ÙˆØ§Ù„ Ø§Ù„Ø§ØªØµØ§Ù„
# ==========================================
TEACHER_KEY = st.secrets.get("TEACHER_MASTER_KEY", "ADMIN")
SHEET_NAME = st.secrets.get("CONTROL_SHEET_NAME", "App_Control")

@st.cache_resource
def get_gspread_client():
    if "gcp_service_account" not in st.secrets: return None
    try:
        creds_dict = dict(st.secrets["gcp_service_account"])
        if "private_key" in creds_dict:
            creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
        scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
        creds = service_account.Credentials.from_service_account_info(creds_dict, scopes=scopes)
        return gspread.authorize(creds)
    except: return None

def check_student_code(input_code):
    client = get_gspread_client()
    if not client: return False
    try:
        sh = client.open(SHEET_NAME)
        real_code = str(sh.sheet1.acell("B1").value).strip()
        return str(input_code).strip() == real_code
    except: return False

# ==========================================
# 5. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ (The Brain)
# ==========================================

# ğŸ§¹ Ø¯Ø§Ù„Ø© ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ² (Ù„Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ù†Ø¬Ù…Ø© Ù†Ø¬Ù…Ø©)
def clean_text_for_speech(text):
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù†Ø¬ÙˆÙ… ÙˆØ§Ù„Ù‡Ø§Ø´ØªØ§Ø¬ ÙˆØ§Ù„Ø´Ø±Ø·Ø§Øª
    clean = re.sub(r'[\*\#\-\_]', '', text)
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
    clean = re.sub(r'\s+', ' ', clean).strip()
    return clean

# ğŸ¤ Ø¯Ø§Ù„Ø© Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† (Ù…Ø­Ø³Ù†Ø©)
def speech_to_text(audio_bytes):
    r = sr.Recognizer()
    try:
        # Ø­ÙØ¸ ÙƒÙ…Ù„Ù WAV Ù…Ø¤Ù‚Øª
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(audio_bytes)
            tmp_filename = tmp_file.name
        
        with sr.AudioFile(tmp_filename) as source:
            # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
            r.adjust_for_ambient_noise(source, duration=0.5)
            audio_data = r.record(source)
            text = r.recognize_google(audio_data, language="ar-EG")
        
        os.remove(tmp_filename)
        return text
    except:
        return None

# ğŸ”Š Ø¯Ø§Ù„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ù„ØµÙˆØª (Ø¨ØµÙˆØª Ø´Ø§ÙƒØ± - Ø±Ø¬Ù„ Ù…ØµØ±ÙŠ)
async def generate_speech_async(text, voice="ar-EG-ShakirNeural"):
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù‚Ø¨Ù„ Ø§Ù„Ù†Ø·Ù‚
    cleaned_text = clean_text_for_speech(text)
    communicate = edge_tts.Communicate(cleaned_text, voice)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
        await communicate.save(tmp_file.name)
        return tmp_file.name

def text_to_speech_pro(text):
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        file_path = loop.run_until_complete(generate_speech_async(text))
        return file_path
    except: return None

# ğŸ§  Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
def get_best_model():
    try:
        models = genai.list_models()
        chat_models = [m.name for m in models if 'generateContent' in m.supported_generation_methods]
        if not chat_models: return 'models/gemini-1.5-flash'
        for m in chat_models:
            if 'flash' in m.lower(): return m
        return chat_models[0]
    except: return 'models/gemini-1.5-flash'

def get_ai_response(user_text, img_obj=None):
    try:
        keys = st.secrets.get("GOOGLE_API_KEYS", [])
        if not keys: return "âš ï¸ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù…ÙÙ‚ÙˆØ¯Ø©."
        genai.configure(api_key=random.choice(keys))
        
        u = st.session_state.user_data
        lang_prompt = "Ø§Ø´Ø±Ø­ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©." if "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" in u['lang'] else "Explain in English."
        
        # ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ù…Ø¹Ù„Ù… (Ø§Ù„Ø±Ø¯ Ø§Ù„Ù…Ø®ØªØµØ±)
        sys_prompt = f"""
        Ø£Ù†Øª Ø§Ù„Ø£Ø³ØªØ§Ø° Ø§Ù„Ø³ÙŠØ¯ Ø§Ù„Ø¨Ø¯ÙˆÙŠ. Ø§Ù„Ø·Ø§Ù„Ø¨: {u['name']} ({u['stage']}-{u['grade']}).
        1. Ø§Ù„ØªØ²Ù… Ø¨Ø§Ù„Ù…Ù†Ù‡Ø¬.
        2. {lang_prompt}
        3. â›” Ø§Ù„Ø±Ø¯ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù…Ø®ØªØµØ±Ø§Ù‹ Ø¬Ø¯Ø§Ù‹ ÙˆÙ…Ø±ÙƒØ²Ø§Ù‹ (Concise Summary).
        4. âœ… Ø§Ø³ØªØ®Ø¯Ù… Ù†Ù‚Ø§Ø· (Bullet points).
        5. ØªØ¬Ù†Ø¨ Ø§Ù„Ù…Ù‚Ø¯Ù…Ø§Øª Ø§Ù„Ø·ÙˆÙŠÙ„Ø©.
        """
        
        model_name = get_best_model()
        model = genai.GenerativeModel(model_name)
        
        inputs = [sys_prompt, user_text]
        if img_obj: inputs.extend([img_obj, "Ø§Ø´Ø±Ø­ Ø§Ù„ØµÙˆØ±Ø©."])
        
        return model.generate_content(inputs).text
    except Exception as e: return f"Ø®Ø·Ø£: {e}"

# ==========================================
# 6. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø§Øª ÙˆØ§Ù„ØªØ´ØºÙŠÙ„
# ==========================================
def login_page():
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.markdown("### ğŸ” ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„")
        with st.form("login"):
            name = st.text_input("Ø§Ù„Ø§Ø³Ù…")
            code = st.text_input("Ø§Ù„ÙƒÙˆØ¯", type="password")
            st.markdown("---")
            c1, c2 = st.columns(2)
            with c1:
                stage = st.selectbox("Ø§Ù„Ù…Ø±Ø­Ù„Ø©", ["Ø§Ù„Ø§Ø¨ØªØ¯Ø§Ø¦ÙŠØ©", "Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ÙŠØ©", "Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©"])
                lang = st.selectbox("Ø§Ù„Ù„ØºØ©", ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"])
            with c2:
                grade = st.selectbox("Ø§Ù„ØµÙ", ["Ø§Ù„Ø±Ø§Ø¨Ø¹", "Ø§Ù„Ø®Ø§Ù…Ø³", "Ø§Ù„Ø³Ø§Ø¯Ø³", "Ø§Ù„Ø£ÙˆÙ„", "Ø§Ù„Ø«Ø§Ù†ÙŠ", "Ø§Ù„Ø«Ø§Ù„Ø«"])
            
            if st.form_submit_button("Ø¯Ø®ÙˆÙ„"):
                if code == TEACHER_KEY:
                    st.session_state.user_data.update({"logged_in": True, "role": "Teacher", "name": name})
                    st.rerun()
                elif check_student_code(code):
                    st.session_state.user_data.update({"logged_in": True, "role": "Student", "name": name, "stage": stage, "grade": grade, "lang": lang})
                    st.rerun()
                else:
                    st.error("Ø§Ù„ÙƒÙˆØ¯ Ø®Ø·Ø£")

def main_app():
    with st.sidebar:
        st.success(f"Ù…Ø±Ø­Ø¨Ø§Ù‹: {st.session_state.user_data['name']}")
        if st.button("Ø®Ø±ÙˆØ¬"):
            st.session_state.user_data["logged_in"] = False
            st.rerun()

    st.subheader("ğŸ’¬ Ø§Ø³Ø£Ù„ Ø§Ù„Ù…Ø¹Ù„Ù… (ØªØ­Ø¯Ø« Ø£Ùˆ Ø§ÙƒØªØ¨)")
    
    c_mic, c_img = st.columns([1, 1])
    with c_mic:
        st.info("ğŸ™ï¸ Ø§Ø¶ØºØ· Ù„Ù„ØªØ­Ø¯Ø«:")
        audio = mic_recorder(start_prompt="Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ âºï¸", stop_prompt="Ø¥Ù†Ù‡Ø§Ø¡ â¹ï¸", key='recorder')
    
    with c_img:
        with st.expander("ğŸ“¸ Ø¥Ø±ÙØ§Ù‚ ØµÙˆØ±Ø©"):
            f = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø©", type=['jpg', 'png'])
            img = Image.open(f) if f else None
            if img: st.image(img, width=150)

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª
    voice_text = None
    if audio:
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª..."):
            voice_text = speech_to_text(audio['bytes'])
            if not voice_text:
                st.warning("âš ï¸ Ø§Ù„ØµÙˆØª ØºÙŠØ± ÙˆØ§Ø¶Ø­ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]): st.write(msg["content"])

    text_input = st.chat_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ...")
    final_q = text_input if text_input else voice_text

    if final_q:
        st.session_state.messages.append({"role": "user", "content": final_q})
        with st.chat_message("user"): st.write(final_q)
        
        with st.chat_message("assistant"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ø¶ÙŠØ±..."):
                resp_text = get_ai_response(final_q, img)
                st.write(resp_text)
                
                # Ø§Ù„ØµÙˆØª (Ø§Ù„Ù†Ø¸ÙŠÙ)
                audio_file = text_to_speech_pro(resp_text)
                if audio_file:
                    st.audio(audio_file, format='audio/mp3')
        
        st.session_state.messages.append({"role": "assistant", "content": resp_text})

if __name__ == "__main__":
    if st.session_state.user_data["logged_in"]:
        main_app()
    else:
        login_page()
